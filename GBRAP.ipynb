{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "startTime = datetime.now()\n",
        "import re\n",
        "import csv\n",
        "import math\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "class GBRAP():\n",
        "    def splitter (self,location):\n",
        "        split=location.split(':')\n",
        "        if len(split)==1: #for cases where only one base position given in gbff\n",
        "            start= int(split[0])\n",
        "            value=(start, start)\n",
        "        else:\n",
        "            start,end=map(int,split)\n",
        "            value=(start, end)\n",
        "        return value\n",
        "\n",
        "    def split_n_append_all (self,i,element_dict):\n",
        "        if 'join' in i:\n",
        "            if 'complement' in i:\n",
        "                strand='neg'\n",
        "                loc=re.search(r'complement\\(join\\((.*?)\\)',i)\n",
        "                if loc: #to avoid errors when strange formats are met (elements with strange format will be skipped)\n",
        "                    location=loc.group(1)\n",
        "                    locatn=re.findall(r'([0-9\\:]+)', location)\n",
        "                    for val in locatn:\n",
        "                        value=self.splitter(val)\n",
        "                        element_dict.append(value)\n",
        "                else:\n",
        "                    print(f'the element with coordinates, {i} was skipped due to being strangly formatted')\n",
        "\n",
        "            else:\n",
        "                strand='pos'\n",
        "                loc=re.search(r'join\\((.*?)\\)',i)\n",
        "                if loc: #to avoid errors when strange formats are met (elements with strange format will be skipped)\n",
        "                    location=loc.group(1)\n",
        "                    locatn=re.findall(r'([0-9\\:]+)', location)\n",
        "                    for val in locatn:\n",
        "                        value=self.splitter(val)\n",
        "                        element_dict.append(value)\n",
        "                else:\n",
        "                    print(f'the element with coordinates, {i} was skipped due to being strangly formatted')\n",
        "        else:\n",
        "            if 'complement' in i:\n",
        "                strand='neg'\n",
        "                loc=re.search(r'complement\\((.*?)\\)',i)\n",
        "                if loc: #to avoid errors when strange formats are met (elements with strange format will be skipped)\n",
        "                    location=loc.group(1)\n",
        "                    locatn=re.findall(r'([0-9\\:]+)', location)\n",
        "                    for val in locatn:\n",
        "                        value=self.splitter(val)\n",
        "                        element_dict.append(value)\n",
        "                else:\n",
        "                    print(f'the element with coordinates, {i} was skipped due to being strangly formatted')\n",
        "            else:\n",
        "                strand='pos'\n",
        "                locatn=re.findall(r'([0-9\\:]+)', i)\n",
        "                if locatn:#to avoid errors when strange formats are met (elements with strange format will be skipped)\n",
        "                    for val in locatn:\n",
        "                        value=self.splitter(val)\n",
        "                        element_dict.append(value)\n",
        "                else:\n",
        "                    print(f'the element with coordinates, {i} was skipped due to being strangly formatted')\n",
        "\n",
        "        return (strand)\n",
        "\n",
        "    def split_n_append_all_list (self,i,isoform_list):\n",
        "        templist=[]\n",
        "        if 'join' in i:\n",
        "            if 'complement' in i:\n",
        "                strand='neg'\n",
        "                loc=re.search(r'complement\\(join\\((.*?)\\)',i)\n",
        "                if loc: #to avoid errors when strange formats are met (elements with strange format will be skipped)\n",
        "                    location=loc.group(1)\n",
        "                    locatn=re.findall(r'([0-9\\:]+)', location)\n",
        "                    for val in locatn:\n",
        "                        value=self.splitter(val)\n",
        "                        templist.append(value)\n",
        "                else:\n",
        "                    print(f'the element with coordinates, {i} was skipped due to being strangly formatted')\n",
        "\n",
        "            else:\n",
        "                strand='pos'\n",
        "                loc=re.search(r'join\\((.*?)\\)',i)\n",
        "                if loc: #to avoid errors when strange formats are met (elements with strange format will be skipped)\n",
        "                    location=loc.group(1)\n",
        "                    locatn=re.findall(r'([0-9\\:]+)', location)\n",
        "                    for val in locatn:\n",
        "                        value=self.splitter(val)\n",
        "                        templist.append(value)\n",
        "                else:\n",
        "                    print(f'the element with coordinates, {i} was skipped due to being strangly formatted')\n",
        "        else:\n",
        "            if 'complement' in i:\n",
        "                strand='neg'\n",
        "                loc=re.search(r'complement\\((.*?)\\)',i)\n",
        "                if loc: #to avoid errors when strange formats are met (elements with strange format will be skipped)\n",
        "                    location=loc.group(1)\n",
        "                    locatn=re.findall(r'([0-9\\:]+)', location)\n",
        "                    for val in locatn:\n",
        "                        value=self.splitter(val)\n",
        "                        templist.append(value)\n",
        "                else:\n",
        "                    print(f'the element with coordinates, {i} was skipped due to being strangly formatted')\n",
        "            else:\n",
        "                strand='pos'\n",
        "                locatn=re.findall(r'([0-9\\:]+)', i)\n",
        "                if locatn:#to avoid errors when strange formats are met (elements with strange format will be skipped)\n",
        "                    for val in locatn:\n",
        "                        value=self.splitter(val)\n",
        "                        templist.append(value)\n",
        "                else:\n",
        "                    print(f'the element with coordinates, {i} was skipped due to being strangly formatted')\n",
        "        isoform_list.append(templist)\n",
        "        return (strand)\n",
        "\n",
        "    def introns (self,cds_list,i,list_dict,strand):\n",
        "        intron=(cds_list[i][1])+1,(cds_list[i+1][0])-1\n",
        "        if strand=='pos':\n",
        "            list_dict['positives'].append(intron)\n",
        "        elif strand=='neg':\n",
        "            list_dict['negatives'].append(intron)\n",
        "\n",
        "    def cordinates (self,i,list_dict,strand):\n",
        "        if strand=='pos':\n",
        "            list_dict['positives'].append(i)\n",
        "        elif strand=='neg':\n",
        "            list_dict['negatives'].append(i)\n",
        "\n",
        "    def cds_selecter (self,seq,list_of_joins,strand):\n",
        "        ''' This select one CDS isoform which satisfy the conditions '''\n",
        "        ''' Conditions:Having only triplets, starting with ATG|GTG,Being the longest '''\n",
        "        chosen_dict={} #to save the real CDS (having 3x and ATG|GTG)\n",
        "        chosen=None #to set the variable empty in case no isoform is selected\n",
        "        if strand == 'pos':\n",
        "            isoform_count=0\n",
        "            for i in list_of_joins:\n",
        "                if len(i)!=0:\n",
        "                    start_codon=seq[(i[0][0])-1:(i[0][0])+2] #the first three bases\n",
        "                    if start_codon == 'atg' or start_codon =='gtg': #selects the sequences starting with a start codon\n",
        "                        count=0\n",
        "                        tot_len=0 #to save the lenght of the isoform\n",
        "                        for j in i:\n",
        "                            short_len=j[1]-(j[0]-1) #the length of one exon\n",
        "                            tot_len+=short_len\n",
        "                            count=count+1\n",
        "                        if tot_len%3==0: #selects the ones that are made of triplets\n",
        "                            chosen_dict[str(isoform_count)]=tot_len\n",
        "                    isoform_count=isoform_count+1 #update the isoform number\n",
        "            if chosen_dict: #to make sure that the dict is not empty\n",
        "                max_key = int(max(chosen_dict, key=lambda k: chosen_dict[k])) #select the key with the highest value and get the int of it\n",
        "                chosen=list_of_joins[max_key] #chosen isoform\n",
        "\n",
        "        elif strand == 'neg':\n",
        "            isoform_count=0\n",
        "            for n in list_of_joins:\n",
        "                if len(n)!=0:\n",
        "                    start_codon=(seq[(n[-1][1])-3]+seq[(n[-1][1])-2]+seq[(n[-1][1])-1]) #the first three bases\n",
        "                    if start_codon == 'cat' or start_codon =='cac': #selects the sequences starting with a start codon\n",
        "                        count=0\n",
        "                        tot_len=0 #to save the lenght of the isoform\n",
        "                        for j in n:\n",
        "                            short_len=j[1]-(j[0]-1) #the length of one exon\n",
        "                            tot_len+=short_len\n",
        "                            count=count+1\n",
        "                        if tot_len%3==0: #selects the ones that are made of triplets\n",
        "                            chosen_dict[str(isoform_count)]=tot_len\n",
        "                    isoform_count=isoform_count+1 #update the isoform number\n",
        "            if chosen_dict: #to make sure that the dict is not empty\n",
        "                max_key = int(max(chosen_dict, key=lambda k: chosen_dict[k])) #select the key with the highest value and get the int of it\n",
        "                chosen=list_of_joins[max_key] #chosen isoform\n",
        "        return chosen\n",
        "\n",
        "    def nc_selecter (self,seq,list_of_joins):\n",
        "        ''' This select one non coding rna isoform which satisfy the conditions '''\n",
        "        ''' Conditions:Being the longest '''\n",
        "        chosen_dict={} #to save the real CDS (having 3x and ATG|GTG)\n",
        "        chosen=None #to set the variable empty in case no isoform is selected\n",
        "        #if strand == 'pos':\n",
        "        isoform_count=0\n",
        "        for i in list_of_joins:\n",
        "            if len(i)!=0:\n",
        "                count=0\n",
        "                tot_len=0 #to save the lenght of the isoform\n",
        "                for j in i:\n",
        "                    short_len=j[1]-(j[0]-1) #the length of one exon\n",
        "                    tot_len+=short_len\n",
        "                    count=count+1\n",
        "                chosen_dict[str(isoform_count)]=tot_len\n",
        "                isoform_count=isoform_count+1 #update the isoform number\n",
        "        if chosen_dict: #to make sure that the dict is not empty\n",
        "            max_key = int(max(chosen_dict, key=lambda k: chosen_dict[k])) #select the key with the highest value and get the int of it\n",
        "            chosen=list_of_joins[max_key] #chosen isoform\n",
        "\n",
        "        # elif strand == 'neg':\n",
        "        #     isoform_count=0\n",
        "        #     for n in list_of_cds:\n",
        "            #    if len(n)!=0:\n",
        "            #         start_codon=(seq[(n[-1][1])-3]+seq[(n[-1][1])-2]+seq[(n[-1][1])-1]) #the first three bases\n",
        "            #         if start_codon == 'cat' or start_codon =='cac':\n",
        "            #             count=0\n",
        "            #             tot_len=0 #to save the lenght of the isoform\n",
        "            #             for j in n:\n",
        "            #                 short_len=j[1]-(j[0]-1) #the length of one exon\n",
        "            #                 tot_len+=short_len\n",
        "            #                 count=count+1\n",
        "            #             if tot_len%3==0:\n",
        "            #                 chosen_dict[str(isoform_count)]=tot_len\n",
        "            #         isoform_count=isoform_count+1 #update the isoform number\n",
        "        #     if chosen_dict: #to make sure that the dict is not empty\n",
        "        #         max_key = int(max(chosen_dict, key=lambda k: chosen_dict[k])) #select the key with the highest value and get the int of it\n",
        "        #         chosen=list_of_cds[max_key] #chosen isoform\n",
        "        return chosen\n",
        "\n",
        "    def element_counter (self,count_dict,strand):\n",
        "        if strand == 'pos':\n",
        "            count_dict['counters']['pos_number']+=1\n",
        "        elif strand == 'neg':\n",
        "            count_dict['counters']['neg_number']+=1\n",
        "\n",
        "    def count_cols (self,count_dict):\n",
        "        col_pos=count_dict['counters']['pos_number']\n",
        "        col_neg=count_dict['counters']['neg_number']\n",
        "        col_tot=col_pos+col_neg\n",
        "\n",
        "        return [col_pos,col_neg,col_tot]\n",
        "\n",
        "    def des_sorter (self,list_dict):\n",
        "        pos_set = set(list_dict['positives'])\n",
        "        neg_set = set(list_dict['negatives'])\n",
        "\n",
        "        pos_sorted = sorted(pos_set, key=lambda x: (x[0],x[1]),reverse=True) #orders the list based on the starting position\n",
        "        neg_sorted = sorted(neg_set, key=lambda x: (x[0],x[1]),reverse=True)\n",
        "\n",
        "        return [pos_sorted,neg_sorted]\n",
        "\n",
        "    def asc_sorter (self,list_dict):\n",
        "        pos_set = set(list_dict['positives'])\n",
        "        neg_set = set(list_dict['negatives'])\n",
        "\n",
        "        pos_sorted = sorted(pos_set, key=lambda x: (x[0],x[1])) #orders the list based on the starting position\n",
        "        neg_sorted = sorted(neg_set, key=lambda x: (x[0],x[1]))\n",
        "\n",
        "        return [pos_sorted,neg_sorted]\n",
        "\n",
        "    def smallest (self,i,sorted_list,del_list,prev_val,prev_val_id):\n",
        "        if prev_val is not None and prev_val[0]<=sorted_list[i][0]  and prev_val[1]>=sorted_list[i][1]:\n",
        "            del_list.append(prev_val_id)\n",
        "            prev_val=sorted_list[i]\n",
        "            prev_val_id=i\n",
        "        elif prev_val is not None and prev_val[0]>=sorted_list[i][0] and prev_val[1]<=sorted_list[i][1]:\n",
        "            del_list.append(i)\n",
        "        else:\n",
        "            prev_val = sorted_list[i]\n",
        "            prev_val_id=i\n",
        "        return prev_val,prev_val_id\n",
        "\n",
        "    def biggest (self,i,sorted_list,del_list,prev_val,prev_val_id):\n",
        "        if prev_val is not None and prev_val[0]>=sorted_list[i][0]  and prev_val[1]<=sorted_list[i][1]:\n",
        "            del_list.append(prev_val_id)\n",
        "            prev_val=sorted_list[i]\n",
        "            prev_val_id=i\n",
        "        elif prev_val is not None and prev_val[0]<=sorted_list[i][0] and prev_val[1]>=sorted_list[i][1]:\n",
        "            del_list.append(i)\n",
        "        else:\n",
        "            prev_val = sorted_list[i]\n",
        "            prev_val_id=i\n",
        "        return prev_val,prev_val_id\n",
        "\n",
        "    def overlaps (self,i,sorted_list,list_dict):\n",
        "        g1_start, g1_end = sorted_list[i]\n",
        "        g2_start, g2_end = sorted_list[i+1]\n",
        "        if g1_start <= g2_end and g2_start <= g1_end:\n",
        "            list_dict.append((g2_start,g1_end))\n",
        "\n",
        "    def seq (self,strand,i,seque):\n",
        "        cdsseq=seque[(i[0]-1):i[1]]\n",
        "        if strand == 'pos':\n",
        "            sequence=cdsseq.upper()\n",
        "        elif strand=='neg':\n",
        "            reverse=cdsseq[::-1]\n",
        "            sequence=reverse.replace('a','T').replace('t','A').replace('g','C').replace('c','G').replace('n','N') #reverse complement\n",
        "        return sequence\n",
        "\n",
        "    # def intron_seq (self,strand,i,seque):\n",
        "    #     intronseq=seque[i[0]:i[1]]\n",
        "    #     if strand == 'pos':\n",
        "    #         sequence=intronseq.upper()\n",
        "    #     elif strand=='neg':\n",
        "    #         reverse=intronseq[::-1]\n",
        "    #         sequence=reverse.replace('a','T').replace('t','A').replace('g','C').replace('c','G').replace('n','N') #reverse complement\n",
        "    #     return sequence\n",
        "\n",
        "\n",
        "    def countbases(self,seq): #class method to count the bases in each element sequence\n",
        "        A=seq.count('A')\n",
        "        C=seq.count('C')\n",
        "        G=seq.count('G')\n",
        "        T=seq.count('T')\n",
        "        N=seq.count('N')\n",
        "        total=A+C+G+T+N\n",
        "        return [total,A,C,G,T,N]\n",
        "\n",
        "    def freq_bases(self,seq,base_counts): #class method to calculate the frequency in each element sequence\n",
        "        #nt=self.countbases(seq)\n",
        "        nt=base_counts\n",
        "        if nt[0]==0:\n",
        "            return 'NA'\n",
        "        else:\n",
        "            pA = float(nt[1]/nt[0])\n",
        "            pC = float(nt[2]/nt[0])\n",
        "            pG = float(nt[3]/nt[0])\n",
        "            pT = float(nt[4]/nt[0])\n",
        "            pN = float(nt[5]/nt[0])\n",
        "            GC = float ((nt[2]+nt[3])/nt[0])\n",
        "            total=pA+pC+pG+pT+pN\n",
        "            return [total,pA,pC,pG,pT,pN,GC]\n",
        "\n",
        "    def chargaff_ct(self,sequence):\n",
        "        ''' perform chargaff score CT '''\n",
        "        counts = Counter(sequence)\n",
        "\n",
        "        def safe_ratio(x, y):\n",
        "            if x == 0 or y == 0:\n",
        "                return 0\n",
        "            return min(x, y) / max(x, y)\n",
        "\n",
        "        a_t_ratio = safe_ratio(counts['A'], counts['T'])\n",
        "        c_g_ratio = safe_ratio(counts['C'], counts['G'])\n",
        "\n",
        "        CT = (a_t_ratio + c_g_ratio) / 2\n",
        "        return CT\n",
        "\n",
        "    def chargaff_pf(self,sequence):\n",
        "        '''chargaff pf'''\n",
        "        counts = Counter(sequence)\n",
        "\n",
        "        def safe_pf(x,y):\n",
        "            if x==0 and y==0:\n",
        "                return 0\n",
        "            return abs((x-y)/(x+y))\n",
        "\n",
        "        a_t=safe_pf(counts['A'],counts['T'])\n",
        "        c_g=safe_pf(counts['C'],counts['G'])\n",
        "\n",
        "        PF=a_t+c_g\n",
        "\n",
        "        return PF\n",
        "\n",
        "    def shannon (self,seq,base_counts):\n",
        "        #s=seq.replace(\"N\",\"\") #Removes the N in the sequence\n",
        "        #nt=self.countbases(s)\n",
        "        nt=base_counts\n",
        "        if nt[0]==0:\n",
        "            return 'NA'\n",
        "        else:\n",
        "            pA = float(nt[1]/nt[0])\n",
        "            pC = float(nt[2]/nt[0])\n",
        "            pG = float(nt[3]/nt[0])\n",
        "            pT = float(nt[4]/nt[0])\n",
        "\n",
        "            if pA == 0:\n",
        "                pA=1\n",
        "            if pC == 0:\n",
        "                pC=1\n",
        "            if pG == 0:\n",
        "                pG=1\n",
        "            if pT == 0:\n",
        "                pT=1\n",
        "\n",
        "            return -((pA*math.log2(pA))+(pT*math.log2(pT))+(pC*math.log2(pC))+(pG*math.log2(pG)))\n",
        "\n",
        "    def topology (self,seq): #Topological Entropy\n",
        "        s=seq.replace(\"N\",\"\") ##Removes the N in the sequence\n",
        "        n = len(set(s)) # number of bases, this is usually equal to 4\n",
        "        length = len(s)\n",
        "        if len(s) != 0 and n > 1: # if len of s is not 0 and number of bases is more than 1\n",
        "            logg = math.floor(math.log(length,n))\n",
        "            neww = (s[:(n**logg + logg)]).lower()\n",
        "            result_mr = math.log(len(set([neww[i:(i+logg)] for i in range(1, n**logg+1)])),n)/logg #the topological entropy score\n",
        "        else:\n",
        "            result_mr = 'NA'\n",
        "        return result_mr\n",
        "\n",
        "    def codon_count (self,sequence,codon_dict):\n",
        "        for i in range(0, len(sequence), 3):\n",
        "            codon = sequence[i:i+3]  # Get a triplet of characters\n",
        "            if codon in codon_dict:\n",
        "                codon_dict[codon] += 1 #saves the count of each codon in the dict\n",
        "\n",
        "    def calculations (self,sequence,g_counters):\n",
        "        #calculates all the output scores and saves the numbers in the relevent key,value in the counter dictionary\n",
        "        nt=self.countbases(sequence)\n",
        "        freq=self.freq_bases(sequence,nt)\n",
        "        charg_ct=self.chargaff_ct(sequence)\n",
        "        charg_pf=self.chargaff_pf(sequence)\n",
        "        shan=self.shannon(sequence,nt)\n",
        "        topo=self.topology(sequence)\n",
        "        ###CALCULATIONS###\n",
        "\n",
        "        #total bases\n",
        "        g_counters['totA']=g_counters['totA']+nt[1]\n",
        "        g_counters['totC']=g_counters['totC']+nt[2]\n",
        "        g_counters['totG']=g_counters['totG']+nt[3]\n",
        "        g_counters['totT']=g_counters['totT']+nt[4]\n",
        "        g_counters['totN']=g_counters['totN']+nt[5]\n",
        "        g_counters['totBase']=g_counters['totBase']+nt[0]\n",
        "\n",
        "        #base frequencies\n",
        "        if type(freq) is str:\n",
        "            pass\n",
        "        else:\n",
        "            g_counters['freqA']=g_counters['freqA']+freq[1]\n",
        "            g_counters['freqC']=g_counters['freqC']+freq[2]\n",
        "            g_counters['freqG']=g_counters['freqG']+freq[3]\n",
        "            g_counters['freqT']=g_counters['freqT']+freq[4]\n",
        "            g_counters['freqN']=g_counters['freqN']+freq[5]\n",
        "            g_counters['freqGC']=g_counters['freqGC']+freq[6]\n",
        "            g_counters['freq_counter']=g_counters['freq_counter']+1\n",
        "\n",
        "        #Chargaff scores\n",
        "        g_counters['tot_PF_charg']=g_counters['tot_PF_charg']+charg_pf\n",
        "        g_counters['tot_CT_charg']=g_counters['tot_CT_charg']+charg_ct\n",
        "        g_counters['chargaff_counter']=g_counters['chargaff_counter']+1\n",
        "\n",
        "        #Shannon\n",
        "        if type(shan) is str:\n",
        "            pass\n",
        "        else:\n",
        "            g_counters['tot_shan']=g_counters['tot_shan']+shan\n",
        "            g_counters['shan_counter']=g_counters['shan_counter']+1\n",
        "\n",
        "        if type(topo) is str:\n",
        "            pass\n",
        "        else:\n",
        "            g_counters['tot_topo']=g_counters['tot_topo']+topo\n",
        "            g_counters['topo_counter']=g_counters['topo_counter']+1\n",
        "\n",
        "        return nt[5]\n",
        "\n",
        "\n",
        "    def outputs (self,g_counters):\n",
        "        column1=g_counters['totA']\n",
        "        column2=g_counters['totT']\n",
        "        column3=g_counters['totC']\n",
        "        column4=g_counters['totG']\n",
        "        column5=g_counters['totN']\n",
        "        column6=g_counters['totBase']\n",
        "\n",
        "        try:    #Mean frequencies of each base in all the genes\n",
        "            column7='{:.2f}'.format(g_counters['freqA']/g_counters['freq_counter'])\n",
        "            column8='{:.2f}'.format(g_counters['freqT']/g_counters['freq_counter'])\n",
        "            column9='{:.2f}'.format(g_counters['freqC']/g_counters['freq_counter'])\n",
        "            column10='{:.2f}'.format(g_counters['freqG']/g_counters['freq_counter'])\n",
        "            column11='{:.2f}'.format(g_counters['freqN']/g_counters['freq_counter'])\n",
        "            column12='{:.2f}'.format(g_counters['freqGC']/g_counters['freq_counter'])\n",
        "        except ZeroDivisionError:\n",
        "            column7=''\n",
        "            column8=''\n",
        "            column9=''\n",
        "            column10=''\n",
        "            column11=''\n",
        "            column12=''\n",
        "\n",
        "        try:    #Mean Topological score all the genes in the locus\n",
        "            column13='{:.4f}'.format(g_counters['tot_topo']/g_counters['topo_counter'])\n",
        "        except ZeroDivisionError:\n",
        "            column13=''\n",
        "\n",
        "        try:    #Mean Chargaff score all the genes in the locus\n",
        "            column14='{:.4f}'.format(g_counters['tot_PF_charg']/g_counters['chargaff_counter'])\n",
        "            column15='{:.4f}'.format(g_counters['tot_CT_charg']/g_counters['chargaff_counter'])\n",
        "        except ZeroDivisionError:\n",
        "            column14=''\n",
        "            column15=''\n",
        "\n",
        "        try:    #Mean Shanon score all the genes in the locus\n",
        "            column16='{:.4f}'.format(g_counters['tot_shan']/g_counters['shan_counter'])\n",
        "        except ZeroDivisionError:\n",
        "            column16=''\n",
        "\n",
        "        return [column1,column2,column3,column4,column5,column6,column7,column8,column9,column10,column11,column12,column13,column14,column15,column16]\n",
        "\n",
        "    def codon_outputs (self,cod_counter):\n",
        "        column1=cod_counter[\"ATG\"]\n",
        "        column2=cod_counter[\"AAG\"]\n",
        "        column3=cod_counter[\"GTA\"]\n",
        "        column4=cod_counter[\"ACT\"]\n",
        "        column5=cod_counter[\"GCA\"]\n",
        "        column6=cod_counter[\"GAG\"]\n",
        "        column7=cod_counter[\"GCT\"]\n",
        "        column8=cod_counter[\"ATT\"]\n",
        "        column9=cod_counter[\"TCC\"]\n",
        "        column10=cod_counter[\"TGG\"]\n",
        "        column11=cod_counter[\"AAT\"]\n",
        "        column12=cod_counter[\"GAA\"]\n",
        "        column13=cod_counter[\"TCA\"]\n",
        "        column14=cod_counter[\"ACG\"]\n",
        "        column15=cod_counter[\"AGT\"]\n",
        "        column16=cod_counter[\"AAC\"]\n",
        "        column17=cod_counter[\"TCT\"]\n",
        "        column18=cod_counter[\"GTG\"]\n",
        "        column19=cod_counter[\"TTC\"]\n",
        "        column20=cod_counter[\"TTT\"]\n",
        "        column21=cod_counter[\"CTG\"]\n",
        "        column22=cod_counter[\"GGT\"]\n",
        "        column23=cod_counter[\"CTC\"]\n",
        "        column24=cod_counter[\"GAT\"]\n",
        "        column25=cod_counter[\"CAG\"]\n",
        "        column26=cod_counter[\"ACC\"]\n",
        "        column27=cod_counter[\"CTA\"]\n",
        "        column28=cod_counter[\"TTG\"]\n",
        "        column29=cod_counter[\"TAT\"]\n",
        "        column30=cod_counter[\"GGA\"]\n",
        "        column31=cod_counter[\"ATC\"]\n",
        "        column32=cod_counter[\"CTT\"]\n",
        "        column33=cod_counter[\"GTC\"]\n",
        "        column34=cod_counter[\"ATA\"]\n",
        "        column35=cod_counter[\"ACA\"]\n",
        "        column36=cod_counter[\"GAC\"]\n",
        "        column37=cod_counter[\"CAC\"]\n",
        "        column38=cod_counter[\"CCC\"]\n",
        "        column39=cod_counter[\"TAC\"]\n",
        "        column40=cod_counter[\"GCC\"]\n",
        "        column41=cod_counter[\"AGC\"]\n",
        "        column42=cod_counter[\"CGC\"]\n",
        "        column43=cod_counter[\"AAA\"]\n",
        "        column44=cod_counter[\"GGC\"]\n",
        "        column45=cod_counter[\"TGC\"]\n",
        "        column46=cod_counter[\"GTT\"]\n",
        "        column47=cod_counter[\"GGG\"]\n",
        "        column48=cod_counter[\"AGA\"]\n",
        "        column49=cod_counter[\"TGT\"]\n",
        "        column50=cod_counter[\"CAT\"]\n",
        "        column51=cod_counter[\"TCG\"]\n",
        "        column52=cod_counter[\"GCG\"]\n",
        "        column53=cod_counter[\"TTA\"]\n",
        "        column54=cod_counter[\"CCT\"]\n",
        "        column55=cod_counter[\"AGG\"]\n",
        "        column56=cod_counter[\"CCA\"]\n",
        "        column57=cod_counter[\"TAG\"]\n",
        "        column58=cod_counter[\"CGG\"]\n",
        "        column59=cod_counter[\"CCG\"]\n",
        "        column60=cod_counter[\"CGT\"]\n",
        "        column61=cod_counter[\"CAA\"]\n",
        "        column62=cod_counter[\"TAA\"]\n",
        "        column63=cod_counter[\"TGA\"]\n",
        "        column64=cod_counter[\"CGA\"]\n",
        "\n",
        "        return [column1, column2, column3, column4, column5, column6, column7, column8, column9, column10, column11, column12, column13, column14, column15, column16, column17, column18, column19, column20, column21, column22, column23, column24, column25, column26, column27, column28, column29, column30, column31, column32, column33, column34, column35, column36, column37, column38, column39, column40, column41, column42, column43, column44, column45, column46, column47, column48, column49, column50, column51, column52, column53, column54, column55, column56, column57, column58, column59, column60, column61, column62, column63, column64]\n",
        "\n",
        "#Add the location and name of the gbff file and a name and a location for the output .csv file\n",
        "#input_file=input(\"please add the path of the input file:\")\n",
        "gbff_file_path = open (input(\"please write the complete name of the input file: \"),\"r\")\n",
        "output_file =input('please write a name for the output file here: ')\n",
        "\n",
        "analysis=input('Please input c for chromosome level analysis and g for whole genome analysis ').lower()\n",
        "\n",
        "if analysis=='g':\n",
        "    output_file_path =f'/content/{output_file}_whole_genome.csv'\n",
        "elif analysis=='c':\n",
        "    output_file_path =f'/content/{output_file}_chromosomal.csv'\n",
        "else:\n",
        "    print (\"\\n##ERROR###\\nThere is a mistake in the input. Please input either 'C' or 'G' only, without spaces\")\n",
        "\n",
        "if analysis==\"g\" or analysis==\"c\":\n",
        "    # Create a new Word document\n",
        "    with open(output_file_path,'w') as outputfile:\n",
        "        outputfile=csv.writer(outputfile)\n",
        "        outputfile.writerow(['Class','Organism','Taxon','Assembly','Locus_ID','Version','Definition',\n",
        "                             'bp_chromo_A','bp_chromo_T','bp_chromo_C','bp_chromo_G','bp_chromo_N','bp_chromo_tot','fr_chromo_A','fr_chromo_T','fr_chromo_C','fr_chromo_G',\n",
        "                             'fr_chromo_N','GC_chromo','topo_entropy_chromo','chargaff_pf_chromo','chargaff_ct_chromo','shannon_chromo',\n",
        "                             'n_gene_pos','n_gene_neg','n_gene_tot','bp_gene_A','bp_gene_T','bp_gene_C','bp_gene_G','bp_gene_N','bp_gene_tot','fr_gene_A','fr_gene_T','fr_gene_C',\n",
        "                             'fr_gene_G','fr_gene_N','GC_gene','topo_entropy_gene','chargaff_pf_gene','chargaff_ct_gene','shannon_gene','bp_gene_overlap_tot',\n",
        "                             'n_cds_pos','n_cds_neg','n_cds_tot','bp_cds_A','bp_cds_T','bp_cds_C','bp_cds_G','bp_cds_N','bp_cds_tot','fr_cds_A','fr_cds_T','fr_cds_C','fr_cds_G',\n",
        "                             'fr_cds_N','GC_cds','topo_entropy_cds','chargaff_pf_cds','chargaff_ct_cds','shannon_cds','bp_cds_overlap_tot',\n",
        "                             'bp_cds_intron_A','bp_cds_intron_T','bp_cds_intron_C','bp_cds_intron_G','bp_cds_intron_N','bp_cds_intron_tot','fr_cds_intron_A','fr_cds_intron_T',\n",
        "                             'fr_cds_intron_C','fr_cds_intron_G','fr_cds_intron_N','GC_cds_intron','topo_entropy_cds_intron','chargaff_pf_cds_intron','chargaff_ct_cds_intron','shannon_cds_intron','bp_cds_intron_overlap_tot',\n",
        "                             'n_ncRNA_pos','n_ncRNA_neg','n_ncRNA_tot','bp_ncRNA_A','bp_ncRNA_T','bp_ncRNA_C','bp_ncRNA_G','bp_ncRNA_N','bp_ncRNA_tot','fr_ncRNA_A','fr_ncRNA_T',\n",
        "                             'fr_ncRNA_C','fr_ncRNA_G','fr_ncRNA_N','GC_ncRNA','topo_entropy_ncRNA','chargaff_pf_ncRNA','chargaff_ct_ncRNA','shannon_ncRNA','bp_ncRNA_overlap_tot',\n",
        "                             'bp_nc_intron_A','bp_nc_intron_T','bp_nc_intron_C','bp_nc_intron_G','bp_nc_intron_N','bp_nc_intron_tot','fr_nc_intron_A','fr_nc_intron_T','fr_nc_intron_C',\n",
        "                             'fr_nc_intron_G','fr_nc_intron_N','GC_nc_intron','topo_entropy_nc_intron','chargaff_pf_nc_intron','chargaff_ct_nc_intron','shannon_nc_intron','bp_nc_intron_overlap_tot',\n",
        "                             'n_tRNA_pos','n_tRNA_neg','n_tRNA_tot','bp_tRNA_A','bp_tRNA_T','bp_tRNA_C','bp_tRNA_G','bp_tRNA_N','bp_tRNA_tot','fr_tRNA_A','fr_tRNA_T','fr_tRNA_C','fr_tRNA_G','fr_tRNA_N',\n",
        "                             'GC_tRNA','topo_entropy_tRNA','chargaff_pf_tRNA','chargaff_ct_tRNA','shannon_tRNA','bp_tRNA_overlap_tot',\n",
        "                             'n_rRNA_pos','n_rRNA_neg','n_rRNA_tot','bp_rRNA_A','bp_rRNA_T','bp_rRNA_C','bp_rRNA_G','bp_rRNA_N','bp_rRNA_tot','fr_rRNA_A','fr_rRNA_T','fr_rRNA_C',\n",
        "                             'fr_rRNA_G','fr_rRNA_N','GC_rRNA','topo_entropy_rRNA','chargaff_pf_rRNA','chargaff_ct_rRNA','shannon_rRNA','bp_rRNA_overlap_tot',\n",
        "                             'ATG','AAG','GTA','ACT','GCA','GAG',\n",
        "                             'GCT','ATT','TCC','TGG','AAT','GAA','TCA','ACG','AGT','AAC','TCT','GTG','TTC','TTT','CTG','GGT','CTC','GAT','CAG','ACC','CTA','TTG','TAT','GGA',\n",
        "                             'ATC','CTT','GTC','ATA','ACA','GAC','CAC','CCC','TAC','GCC','AGC','CGC','AAA','GGC','TGC','GTT','GGG','AGA','TGT','CAT','TCG','GCG','TTA','CCT','AGG',\n",
        "                             'CCA','TAG','CGG','CCG','CGT','CAA','TAA','TGA','CGA'])\n",
        "\n",
        "        gbrp_obj=GBRAP()\n",
        "\n",
        "\n",
        "\n",
        "        #to save the counts of whole genome\n",
        "        genome={'chromodicts':{'counters':{'pos_number':0,'neg_number':0,'totA':0,'totC':0,'totG':0,'totT':0,'totN':0,'totBase':0,'freqA':0,'freqC':0,'freqG':0,'freqT':0,'freqN':0,'freqGC':0,'freq_counter':0,\n",
        "                            'tot_PF_charg':0,'tot_CT_charg':0,'chargaff_counter':0,'tot_shan':0,'shan_counter':0,'tot_topo':0,'topo_counter':0}},\n",
        "        'genedicts':{'counters':{'pos_number':0,'neg_number':0,'totA':0,'totC':0,'totG':0,'totT':0,'totN':0,'totBase':0,'freqA':0,'freqC':0,'freqG':0,'freqT':0,'freqN':0,'freqGC':0,'freq_counter':0,\n",
        "                            'tot_PF_charg':0,'tot_CT_charg':0,'chargaff_counter':0,'tot_shan':0,'shan_counter':0,'tot_topo':0,'topo_counter':0},\n",
        "                    'overlap_counters':{'pos_number':0,'neg_number':0,'totA':0,'totC':0,'totG':0,'totT':0,'totN':0,'totBase':0,'freqA':0,'freqC':0,'freqG':0,'freqT':0,'freqN':0,'freqGC':0,'freq_counter':0,\n",
        "                            'tot_PF_charg':0,'tot_CT_charg':0,'chargaff_counter':0,'tot_shan':0,'shan_counter':0,'tot_topo':0,'topo_counter':0}},\n",
        "        'cdsdicts':{'counters':{'pos_number':0,'neg_number':0,'totA':0,'totC':0,'totG':0,'totT':0,'totN':0,'totBase':0,'freqA':0,'freqC':0,'freqG':0,'freqT':0,'freqN':0,'freqGC':0,'freq_counter':0,\n",
        "                          'tot_PF_charg':0,'tot_CT_charg':0,'chargaff_counter':0,'tot_shan':0,'shan_counter':0,'tot_topo':0,'topo_counter':0},\n",
        "                  'overlap_counters':{'pos_number':0,'neg_number':0,'totA':0,'totC':0,'totG':0,'totT':0,'totN':0,'totBase':0,'freqA':0,'freqC':0,'freqG':0,'freqT':0,'freqN':0,'freqGC':0,'freq_counter':0,\n",
        "                          'tot_PF_charg':0,'tot_CT_charg':0,'chargaff_counter':0,'tot_shan':0,'shan_counter':0,'tot_topo':0,'topo_counter':0},\n",
        "                  'nucl_codon_counter':{'ATG': 0, 'AAG': 0, 'GTA': 0, 'ACT': 0, 'GCA': 0, 'GAG': 0, 'GCT': 0, 'ATT': 0, 'TCC': 0, 'TGG': 0, 'AAT': 0, 'GAA': 0, 'TCA': 0, 'ACG': 0,\n",
        "                                     'AGT': 0, 'AAC': 0, 'TCT': 0, 'GTG': 0, 'TTC': 0, 'TTT': 0, 'CTG': 0, 'GGT': 0, 'CTC': 0, 'GAT': 0, 'CAG': 0, 'ACC': 0, 'CTA': 0, 'TTG': 0,\n",
        "                                     'TAT': 0, 'GGA': 0, 'ATC': 0, 'CTT': 0, 'GTC': 0, 'ATA': 0, 'ACA': 0, 'GAC': 0, 'CAC': 0, 'CCC': 0, 'TAC': 0, 'GCC': 0, 'AGC': 0, 'CGC': 0,\n",
        "                                     'AAA': 0, 'GGC': 0, 'TGC': 0, 'GTT': 0, 'GGG': 0, 'AGA': 0, 'TGT': 0, 'CAT': 0, 'TCG': 0, 'GCG': 0, 'TTA': 0, 'CCT': 0, 'AGG': 0, 'CCA': 0,\n",
        "                                     'TAG': 0, 'CGG': 0, 'CCG': 0, 'CGT': 0, 'CAA': 0, 'TAA': 0, 'TGA': 0, 'CGA': 0}},\n",
        "        'cds_introndicts':{'counters':{'pos_number':0,'neg_number':0,'totA':0,'totC':0,'totG':0,'totT':0,'totN':0,'totBase':0,'freqA':0,'freqC':0,'freqG':0,'freqT':0,'freqN':0,'freqGC':0,'freq_counter':0,\n",
        "                          'tot_PF_charg':0,'tot_CT_charg':0,'chargaff_counter':0,'tot_shan':0,'shan_counter':0,'tot_topo':0,'topo_counter':0},\n",
        "                  'overlap_counters':{'pos_number':0,'neg_number':0,'totA':0,'totC':0,'totG':0,'totT':0,'totN':0,'totBase':0,'freqA':0,'freqC':0,'freqG':0,'freqT':0,'freqN':0,'freqGC':0,'freq_counter':0,\n",
        "                          'tot_PF_charg':0,'tot_CT_charg':0,'chargaff_counter':0,'tot_shan':0,'shan_counter':0,'tot_topo':0,'topo_counter':0}},\n",
        "        'ncRNAdicts':{'counters':{'pos_number':0,'neg_number':0,'totA':0,'totC':0,'totG':0,'totT':0,'totN':0,'totBase':0,'freqA':0,'freqC':0,'freqG':0,'freqT':0,'freqN':0,'freqGC':0,'freq_counter':0,\n",
        "                          'tot_PF_charg':0,'tot_CT_charg':0,'chargaff_counter':0,'tot_shan':0,'shan_counter':0,'tot_topo':0,'topo_counter':0},\n",
        "                  'overlap_counters':{'pos_number':0,'neg_number':0,'totA':0,'totC':0,'totG':0,'totT':0,'totN':0,'totBase':0,'freqA':0,'freqC':0,'freqG':0,'freqT':0,'freqN':0,'freqGC':0,'freq_counter':0,\n",
        "                          'tot_PF_charg':0,'tot_CT_charg':0,'chargaff_counter':0,'tot_shan':0,'shan_counter':0,'tot_topo':0,'topo_counter':0}},\n",
        "        'nc_introndicts':{'counters':{'pos_number':0,'neg_number':0,'totA':0,'totC':0,'totG':0,'totT':0,'totN':0,'totBase':0,'freqA':0,'freqC':0,'freqG':0,'freqT':0,'freqN':0,'freqGC':0,'freq_counter':0,\n",
        "                          'tot_PF_charg':0,'tot_CT_charg':0,'chargaff_counter':0,'tot_shan':0,'shan_counter':0,'tot_topo':0,'topo_counter':0},\n",
        "                  'overlap_counters':{'pos_number':0,'neg_number':0,'totA':0,'totC':0,'totG':0,'totT':0,'totN':0,'totBase':0,'freqA':0,'freqC':0,'freqG':0,'freqT':0,'freqN':0,'freqGC':0,'freq_counter':0,\n",
        "                          'tot_PF_charg':0,'tot_CT_charg':0,'chargaff_counter':0,'tot_shan':0,'shan_counter':0,'tot_topo':0,'topo_counter':0}},\n",
        "        'tRNAdicts':{'counters':{'pos_number':0,'neg_number':0,'totA':0,'totC':0,'totG':0,'totT':0,'totN':0,'totBase':0,'freqA':0,'freqC':0,'freqG':0,'freqT':0,'freqN':0,'freqGC':0,'freq_counter':0,\n",
        "                          'tot_PF_charg':0,'tot_CT_charg':0,'chargaff_counter':0,'tot_shan':0,'shan_counter':0,'tot_topo':0,'topo_counter':0},\n",
        "                  'overlap_counters':{'pos_number':0,'neg_number':0,'totA':0,'totC':0,'totG':0,'totT':0,'totN':0,'totBase':0,'freqA':0,'freqC':0,'freqG':0,'freqT':0,'freqN':0,'freqGC':0,'freq_counter':0,\n",
        "                          'tot_PF_charg':0,'tot_CT_charg':0,'chargaff_counter':0,'tot_shan':0,'shan_counter':0,'tot_topo':0,'topo_counter':0}},\n",
        "        'rRNAdicts':{'counters':{'pos_number':0,'neg_number':0,'totA':0,'totC':0,'totG':0,'totT':0,'totN':0,'totBase':0,'freqA':0,'freqC':0,'freqG':0,'freqT':0,'freqN':0,'freqGC':0,'freq_counter':0,\n",
        "                          'tot_PF_charg':0,'tot_CT_charg':0,'chargaff_counter':0,'tot_shan':0,'shan_counter':0,'tot_topo':0,'topo_counter':0},\n",
        "                  'overlap_counters':{'pos_number':0,'neg_number':0,'totA':0,'totC':0,'totG':0,'totT':0,'totN':0,'totBase':0,'freqA':0,'freqC':0,'freqG':0,'freqT':0,'freqN':0,'freqGC':0,'freq_counter':0,\n",
        "                          'tot_PF_charg':0,'tot_CT_charg':0,'chargaff_counter':0,'tot_shan':0,'shan_counter':0,'tot_topo':0,'topo_counter':0}}}\n",
        "\n",
        "        locus_counter=1\n",
        "        skipped=0\n",
        "        analysed_chromo=0\n",
        "        for result in re.findall('LOCUS(.*?)//\\n',gbff_file_path.read(), re.S): #takes all the info in each locus\n",
        "            if locus_counter==1: #takes the domain name of the organism\n",
        "                org=re.search(r'ORGANISM\\s{2}(.*)\\n\\s*([a-zA-Z;\\s]+).',result)\n",
        "                taxa=org.group(2).replace(' ','').replace('\\n','')\n",
        "                organism=org.group(1).replace(' ','_') #gets the organism name\n",
        "                print(f'\\nGBRAP Analysis started for {organism}\\n--')\n",
        "\n",
        "                category_dict={'Mammal':['Mammalia'],'Amphibia':['Amphibia'],'Reptile':['Lepidosauria','Crocodylia','Testudines'],'Bird':['Aves,'],\n",
        "                             'Fish':['Dipnomorpha','Actinopterygii','Chondrichthyes','Cyclostomata','Coelacanthiformes'],'Plant':['Viridiplantae','Rhodophyta'],\n",
        "                             'Protozoa':['Sar,','Discoba','Amoebozoa','Metamonada','Cryptophyceae'],'Fungi':['Fungi'],'Bacteria':['Bacteria'],'Archaea':['Archaea'],'Virus':['Viruses'],\n",
        "                             'Invertebrate':['Arthropoda','Cephalochordata','Tunicata','Nematoda','Cnidaria','Mollusca','Echinodermata','Hemichordata','Platyhelminthes','Ctenophora','Porifera','Brachiopoda','Choanoflagellata','Scalidophora','Xenacoelomorpha']}\n",
        "\n",
        "                category = 'Not_classified'\n",
        "                for key, values in category_dict.items():\n",
        "                    if any(value in taxa.split(';') for value in values):  #taxa.split to exactly match values with the complete words in taxa (ex in viral the taxa level, Mammalianorthoreovirus contains Mammalian)\n",
        "                        category=key\n",
        "                        break\n",
        "\n",
        "\n",
        "            # if locus_counter==2: #to stop the code after the desired number of locus\n",
        "            #     break\n",
        "\n",
        "            definition=re.search(r'DEFINITION(.*?)ACCESSION',result,re.S) #takes the definition of the locus\n",
        "            col2=definition.group(1).strip().replace('  ','').replace('\\n',' ').replace(',',';') #prints the definition\n",
        "            #Any sequence which contains either of the followings words in the DEFINITION will be removed from the analysis.\n",
        "            skiplocus=['scaffold','unlocalized','contig','unplaced','patch','unknown']\n",
        "            if any (word in definition.group(1).lower() for word in skiplocus):\n",
        "                skipped=skipped+1\n",
        "\n",
        "            else:\n",
        "                analysed_chromo+=1\n",
        "                locus_counter=locus_counter+1\n",
        "\n",
        "                locusline=re.search(r'\\s{7}([a-zA-Z_0-9]+)\\s+[0-9]+\\sbp', result) #takes the locus name\n",
        "                col1=locusline.group(1) #prints the locus name\n",
        "\n",
        "                ver=re.search(r'VERSION\\s{5}(.*?)\\n',result)\n",
        "                if ver is not None:\n",
        "                    version=ver.group(1)\n",
        "                else:\n",
        "                    version='NA'\n",
        "\n",
        "                ass=re.search(r'\\s{12}Assembly:\\s(.*?)\\n',result)\n",
        "                if ass is not None:\n",
        "                    assembly=ass.group(1)\n",
        "                else:\n",
        "                    assembly='NA'\n",
        "\n",
        "                fullseq=re.findall('ORIGIN\\s*\\n\\s*(.*)',result,re.S) #takes the sequence region of the locus from the gbff\n",
        "                se=[g.replace(' ','').replace('\\n','').replace('\\t','') for g in fullseq] #replaces the \\s \\n and \\t\n",
        "                seq=re.sub(\"[^a-zA-Z]\",\"\",str(se).lower())   #the whole sequene of the locus ready to use removes the numbers\n",
        "                features=re.search(r'FEATURES\\s*Location/Qualifiers(.*?)ORIGIN',result,re.S) #takes all the details of the annotations\n",
        "                chromodicts={'counters':{'pos_number':0,'neg_number':0,'totA':0,'totC':0,'totG':0,'totT':0,'totN':0,'totBase':0,'freqA':0,'freqC':0,'freqG':0,'freqT':0,'freqN':0,'freqGC':0,'freq_counter':0,\n",
        "                                    'tot_PF_charg':0,'tot_CT_charg':0,'chargaff_counter':0,'tot_shan':0,'shan_counter':0,'tot_topo':0,'topo_counter':0}}\n",
        "                genedicts={'lists':{'positives':[],'negatives':[],'pos_overlaps':[],'neg_overlaps':[]},\n",
        "                            'counters':{'pos_number':0,'neg_number':0,'totA':0,'totC':0,'totG':0,'totT':0,'totN':0,'totBase':0,'freqA':0,'freqC':0,'freqG':0,'freqT':0,'freqN':0,'freqGC':0,'freq_counter':0,\n",
        "                                    'tot_PF_charg':0,'tot_CT_charg':0,'chargaff_counter':0,'tot_shan':0,'shan_counter':0,'tot_topo':0,'topo_counter':0},\n",
        "                            'overlap_counters':{'pos_number':0,'neg_number':0,'totA':0,'totC':0,'totG':0,'totT':0,'totN':0,'totBase':0,'freqA':0,'freqC':0,'freqG':0,'freqT':0,'freqN':0,'freqGC':0,'freq_counter':0,\n",
        "                                    'tot_PF_charg':0,'tot_CT_charg':0,'chargaff_counter':0,'tot_shan':0,'shan_counter':0,'tot_topo':0,'topo_counter':0}}\n",
        "                cdsdicts={'lists':{'positives':[],'negatives':[],'pos_overlaps':[],'neg_overlaps':[]},\n",
        "                          'counters':{'pos_number':0,'neg_number':0,'totA':0,'totC':0,'totG':0,'totT':0,'totN':0,'totBase':0,'freqA':0,'freqC':0,'freqG':0,'freqT':0,'freqN':0,'freqGC':0,'freq_counter':0,\n",
        "                                  'tot_PF_charg':0,'tot_CT_charg':0,'chargaff_counter':0,'tot_shan':0,'shan_counter':0,'tot_topo':0,'topo_counter':0},\n",
        "                          'overlap_counters':{'pos_number':0,'neg_number':0,'totA':0,'totC':0,'totG':0,'totT':0,'totN':0,'totBase':0,'freqA':0,'freqC':0,'freqG':0,'freqT':0,'freqN':0,'freqGC':0,'freq_counter':0,\n",
        "                                  'tot_PF_charg':0,'tot_CT_charg':0,'chargaff_counter':0,'tot_shan':0,'shan_counter':0,'tot_topo':0,'topo_counter':0},\n",
        "                          'nucl_codon_counter':{'ATG': 0, 'AAG': 0, 'GTA': 0, 'ACT': 0, 'GCA': 0, 'GAG': 0, 'GCT': 0, 'ATT': 0, 'TCC': 0, 'TGG': 0, 'AAT': 0, 'GAA': 0, 'TCA': 0, 'ACG': 0,\n",
        "                                             'AGT': 0, 'AAC': 0, 'TCT': 0, 'GTG': 0, 'TTC': 0, 'TTT': 0, 'CTG': 0, 'GGT': 0, 'CTC': 0, 'GAT': 0, 'CAG': 0, 'ACC': 0, 'CTA': 0, 'TTG': 0,\n",
        "                                             'TAT': 0, 'GGA': 0, 'ATC': 0, 'CTT': 0, 'GTC': 0, 'ATA': 0, 'ACA': 0, 'GAC': 0, 'CAC': 0, 'CCC': 0, 'TAC': 0, 'GCC': 0, 'AGC': 0, 'CGC': 0,\n",
        "                                             'AAA': 0, 'GGC': 0, 'TGC': 0, 'GTT': 0, 'GGG': 0, 'AGA': 0, 'TGT': 0, 'CAT': 0, 'TCG': 0, 'GCG': 0, 'TTA': 0, 'CCT': 0, 'AGG': 0, 'CCA': 0,\n",
        "                                             'TAG': 0, 'CGG': 0, 'CCG': 0, 'CGT': 0, 'CAA': 0, 'TAA': 0, 'TGA': 0, 'CGA': 0},\n",
        "                          'overlap_nucl_codon_counter':{'ATG': 0, 'AAG': 0, 'GTA': 0, 'ACT': 0, 'GCA': 0, 'GAG': 0, 'GCT': 0, 'ATT': 0, 'TCC': 0, 'TGG': 0, 'AAT': 0, 'GAA': 0, 'TCA': 0, 'ACG': 0,\n",
        "                                             'AGT': 0, 'AAC': 0, 'TCT': 0, 'GTG': 0, 'TTC': 0, 'TTT': 0, 'CTG': 0, 'GGT': 0, 'CTC': 0, 'GAT': 0, 'CAG': 0, 'ACC': 0, 'CTA': 0, 'TTG': 0,\n",
        "                                             'TAT': 0, 'GGA': 0, 'ATC': 0, 'CTT': 0, 'GTC': 0, 'ATA': 0, 'ACA': 0, 'GAC': 0, 'CAC': 0, 'CCC': 0, 'TAC': 0, 'GCC': 0, 'AGC': 0, 'CGC': 0,\n",
        "                                             'AAA': 0, 'GGC': 0, 'TGC': 0, 'GTT': 0, 'GGG': 0, 'AGA': 0, 'TGT': 0, 'CAT': 0, 'TCG': 0, 'GCG': 0, 'TTA': 0, 'CCT': 0, 'AGG': 0, 'CCA': 0,\n",
        "                                             'TAG': 0, 'CGG': 0, 'CCG': 0, 'CGT': 0, 'CAA': 0, 'TAA': 0, 'TGA': 0, 'CGA': 0}}\n",
        "                cds_introndicts={'lists':{'positives':[],'negatives':[],'pos_overlaps':[],'neg_overlaps':[]},\n",
        "                          'counters':{'pos_number':0,'neg_number':0,'totA':0,'totC':0,'totG':0,'totT':0,'totN':0,'totBase':0,'freqA':0,'freqC':0,'freqG':0,'freqT':0,'freqN':0,'freqGC':0,'freq_counter':0,\n",
        "                                  'tot_PF_charg':0,'tot_CT_charg':0,'chargaff_counter':0,'tot_shan':0,'shan_counter':0,'tot_topo':0,'topo_counter':0},\n",
        "                          'overlap_counters':{'pos_number':0,'neg_number':0,'totA':0,'totC':0,'totG':0,'totT':0,'totN':0,'totBase':0,'freqA':0,'freqC':0,'freqG':0,'freqT':0,'freqN':0,'freqGC':0,'freq_counter':0,\n",
        "                                  'tot_PF_charg':0,'tot_CT_charg':0,'chargaff_counter':0,'tot_shan':0,'shan_counter':0,'tot_topo':0,'topo_counter':0}}\n",
        "                ncRNAdicts={'lists':{'positives':[],'negatives':[],'pos_overlaps':[],'neg_overlaps':[]},\n",
        "                          'counters':{'pos_number':0,'neg_number':0,'totA':0,'totC':0,'totG':0,'totT':0,'totN':0,'totBase':0,'freqA':0,'freqC':0,'freqG':0,'freqT':0,'freqN':0,'freqGC':0,'freq_counter':0,\n",
        "                                  'tot_PF_charg':0,'tot_CT_charg':0,'chargaff_counter':0,'tot_shan':0,'shan_counter':0,'tot_topo':0,'topo_counter':0},\n",
        "                          'overlap_counters':{'pos_number':0,'neg_number':0,'totA':0,'totC':0,'totG':0,'totT':0,'totN':0,'totBase':0,'freqA':0,'freqC':0,'freqG':0,'freqT':0,'freqN':0,'freqGC':0,'freq_counter':0,\n",
        "                                  'tot_PF_charg':0,'tot_CT_charg':0,'chargaff_counter':0,'tot_shan':0,'shan_counter':0,'tot_topo':0,'topo_counter':0}}\n",
        "                nc_introndicts={'lists':{'positives':[],'negatives':[],'pos_overlaps':[],'neg_overlaps':[]},\n",
        "                          'counters':{'pos_number':0,'neg_number':0,'totA':0,'totC':0,'totG':0,'totT':0,'totN':0,'totBase':0,'freqA':0,'freqC':0,'freqG':0,'freqT':0,'freqN':0,'freqGC':0,'freq_counter':0,\n",
        "                                  'tot_PF_charg':0,'tot_CT_charg':0,'chargaff_counter':0,'tot_shan':0,'shan_counter':0,'tot_topo':0,'topo_counter':0},\n",
        "                          'overlap_counters':{'pos_number':0,'neg_number':0,'totA':0,'totC':0,'totG':0,'totT':0,'totN':0,'totBase':0,'freqA':0,'freqC':0,'freqG':0,'freqT':0,'freqN':0,'freqGC':0,'freq_counter':0,\n",
        "                                  'tot_PF_charg':0,'tot_CT_charg':0,'chargaff_counter':0,'tot_shan':0,'shan_counter':0,'tot_topo':0,'topo_counter':0}}\n",
        "                tRNAdicts={'lists':{'positives':[],'negatives':[],'pos_overlaps':[],'neg_overlaps':[]},\n",
        "                          'counters':{'pos_number':0,'neg_number':0,'totA':0,'totC':0,'totG':0,'totT':0,'totN':0,'totBase':0,'freqA':0,'freqC':0,'freqG':0,'freqT':0,'freqN':0,'freqGC':0,'freq_counter':0,\n",
        "                                  'tot_PF_charg':0,'tot_CT_charg':0,'chargaff_counter':0,'tot_shan':0,'shan_counter':0,'tot_topo':0,'topo_counter':0},\n",
        "                          'overlap_counters':{'pos_number':0,'neg_number':0,'totA':0,'totC':0,'totG':0,'totT':0,'totN':0,'totBase':0,'freqA':0,'freqC':0,'freqG':0,'freqT':0,'freqN':0,'freqGC':0,'freq_counter':0,\n",
        "                                  'tot_PF_charg':0,'tot_CT_charg':0,'chargaff_counter':0,'tot_shan':0,'shan_counter':0,'tot_topo':0,'topo_counter':0}}\n",
        "                rRNAdicts={'lists':{'positives':[],'negatives':[],'pos_overlaps':[],'neg_overlaps':[]},\n",
        "                          'counters':{'pos_number':0,'neg_number':0,'totA':0,'totC':0,'totG':0,'totT':0,'totN':0,'totBase':0,'freqA':0,'freqC':0,'freqG':0,'freqT':0,'freqN':0,'freqGC':0,'freq_counter':0,\n",
        "                                  'tot_PF_charg':0,'tot_CT_charg':0,'chargaff_counter':0,'tot_shan':0,'shan_counter':0,'tot_topo':0,'topo_counter':0},\n",
        "                          'overlap_counters':{'pos_number':0,'neg_number':0,'totA':0,'totC':0,'totG':0,'totT':0,'totN':0,'totBase':0,'freqA':0,'freqC':0,'freqG':0,'freqT':0,'freqN':0,'freqGC':0,'freq_counter':0,\n",
        "                                  'tot_PF_charg':0,'tot_CT_charg':0,'chargaff_counter':0,'tot_shan':0,'shan_counter':0,'tot_topo':0,'topo_counter':0}}\n",
        "                gene_counter=1\n",
        "                for each in re.findall(r'\\s{5}gene\\s{12}.*?(?=\\s{5}gene\\s{12}|$)',features.group(1),re.S):#for each set of gene\n",
        "                    # if gene_counter==2: #to stop after a certain number of genes in the locus\n",
        "                    #     break\n",
        "                    if '/pseudo' in each: ###maybe have to use a different word (ex 'LOC[0-9]+')####\n",
        "                        pass\n",
        "                    else:\n",
        "                        gene_counter+=1\n",
        "                        note=re.search(r'\\s{21}/note=\"([^\"]+)\"', each) #checks for the note\n",
        "                        if note:\n",
        "                            prot_info=note.group(1) #saves the info in note\n",
        "                        else:\n",
        "                            prot_info='' #to avoid erros if note does not exist\n",
        "\n",
        "                        gene=re.findall(r'\\s{5}gene\\s{12}(.*?)\\/',each,re.S)#a list of all the positions of the desired element\n",
        "                        clean_gene =[g.replace(' ','').replace('\\n','').replace('\\t','').replace('..',':')\n",
        "                                      .replace('<','').replace('>','') for g in gene] #the list of the posit\n",
        "                        genedict=[]\n",
        "                        for i in clean_gene:\n",
        "                            strand=gbrp_obj.split_n_append_all(i,genedict) #splits the joined parts in one isoform\n",
        "                        if genedict != None:\n",
        "                            gbrp_obj.element_counter(genedicts,strand)\n",
        "                        for v in genedict:\n",
        "                            gbrp_obj.cordinates(v,genedicts['lists'],strand)\n",
        "\n",
        "                        cds=re.findall(r'\\s{5}CDS\\s{13}(.*?)\\/',each,re.S)#a list of all the positions of the desired element\n",
        "                        clean_cds =[g.replace(' ','').replace('\\n','').replace('\\t','').replace('..',':')\n",
        "                                      .replace('<','').replace('>','') for g in cds] #the list of the posit\n",
        "                        if 'ribosomal' in prot_info:\n",
        "                            cds_type=\"Ribo\"\n",
        "                        else:\n",
        "                            cds_type=\"Nucl\"\n",
        "                        #exonlist=[] #a dict is needed when taking introns of each isoform\n",
        "                        #tempdict={}\n",
        "                        isoforms=[]\n",
        "                        for i in clean_cds:\n",
        "                            strand=gbrp_obj.split_n_append_all_list(i,isoforms) #splits the joined parts in one isoform\n",
        "                        chosen_CDS=gbrp_obj.cds_selecter(seq,isoforms, strand)\n",
        "                        if chosen_CDS != None:\n",
        "                            gbrp_obj.element_counter(cdsdicts,strand)\n",
        "                            for v in chosen_CDS:\n",
        "                                gbrp_obj.cordinates(v,cdsdicts['lists'],strand)\n",
        "                            for i in range (len(chosen_CDS)-1): #introns from CDS\n",
        "                                gbrp_obj.introns(chosen_CDS, i, cds_introndicts['lists'],strand)\n",
        "\n",
        "\n",
        "                        ncrna=re.findall(r'\\s{5}ncRNA\\s{11}(.*?)\\/',each,re.S)#a list of all the positions of the desired element\n",
        "                        clean_ncrna =[g.replace(' ','').replace('\\n','').replace('\\t','').replace('..',':')\n",
        "                                      .replace('<','').replace('>','') for g in ncrna] #the list of the posit\n",
        "                        ncdict=[] #a dict is needed when taking introns of each isoform\n",
        "                        for i in clean_ncrna:\n",
        "                            strand=gbrp_obj.split_n_append_all_list(i,ncdict) #splits the joined parts in one isoform\n",
        "                        chosen_nc=gbrp_obj.nc_selecter(seq,ncdict)\n",
        "                        if chosen_nc != None:\n",
        "                            gbrp_obj.element_counter(ncRNAdicts,strand)\n",
        "                            for v in chosen_nc:\n",
        "                                gbrp_obj.cordinates(v,ncRNAdicts['lists'],strand)\n",
        "                            for i in range (len(chosen_nc)-1): #introns from CDS\n",
        "                                gbrp_obj.introns(chosen_nc, i, nc_introndicts['lists'],strand)\n",
        "\n",
        "\n",
        "                        trna=re.findall(r'\\s{5}tRNA\\s{12}(.*?)\\/',each,re.S)#a list of all the positions of the desired element\n",
        "                        clean_trna =[g.replace(' ','').replace('\\n','').replace('\\t','').replace('..',':')\n",
        "                                      .replace('<','').replace('>','') for g in trna] #the list of the posit\n",
        "                        trnadict=[] #a dict is needed when taking introns of each isoform\n",
        "                        for i in clean_trna:\n",
        "                            strand=gbrp_obj.split_n_append_all_list(i,trnadict) #splits the joined parts in one isoform\n",
        "                        chosen_trna=gbrp_obj.nc_selecter(seq,trnadict)\n",
        "                        if chosen_trna != None:\n",
        "                            gbrp_obj.element_counter(tRNAdicts,strand)\n",
        "                            for v in chosen_trna:\n",
        "                                gbrp_obj.cordinates(v,tRNAdicts['lists'],strand)\n",
        "\n",
        "                        rrna=re.findall(r'\\s{5}rRNA\\s{12}(.*?)\\/',each,re.S)#a list of all the positions of the desired element\n",
        "                        clean_rrna =[g.replace(' ','').replace('\\n','').replace('\\t','').replace('..',':')\n",
        "                                      .replace('<','').replace('>','') for g in rrna] #the list of the posit\n",
        "                        rrnadict=[] #a dict is needed when taking introns of each isoform\n",
        "                        for i in clean_rrna:\n",
        "                            strand=gbrp_obj.split_n_append_all_list(i,rrnadict) #splits the joined parts in one isoform\n",
        "                        chosen_rrna=gbrp_obj.nc_selecter(seq,rrnadict)\n",
        "                        if chosen_rrna != None:\n",
        "                            gbrp_obj.element_counter(rRNAdicts,strand)\n",
        "                            for v in chosen_rrna:\n",
        "                                gbrp_obj.cordinates(v,rRNAdicts['lists'],strand)\n",
        "\n",
        "\n",
        "                #element count outputs\n",
        "                gen_counts=gbrp_obj.count_cols(genedicts)\n",
        "                cds_counts=gbrp_obj.count_cols(cdsdicts)\n",
        "                nc_counts=gbrp_obj.count_cols(ncRNAdicts)\n",
        "                tr_counts=gbrp_obj.count_cols(tRNAdicts)\n",
        "                rr_counts=gbrp_obj.count_cols(rRNAdicts)\n",
        "\n",
        "                #Calculations and Outputs starts from here#\n",
        "                ####Whole chromosome####\n",
        "                sequence=seq.upper()\n",
        "                gbrp_obj.calculations (sequence,chromodicts['counters'])\n",
        "                chromo_cols=gbrp_obj.outputs(chromodicts['counters'])\n",
        "\n",
        "                #####GENE####\n",
        "                gene_sorts=gbrp_obj.asc_sorter(genedicts['lists'])#sorts the list and removes duplicates\n",
        "                #pos gene filtering\n",
        "                gen_pos_to_del = []\n",
        "                gen_pos_prev_value = None\n",
        "                gen_pos_prev_value_index=None\n",
        "                for i in range(len(gene_sorts[0])): #deletes the smaller ones, keeping the biggest gene\n",
        "                    gen_pos_prev_value,gen_pos_prev_value_index=gbrp_obj.biggest(i, gene_sorts[0], gen_pos_to_del,gen_pos_prev_value,gen_pos_prev_value_index)\n",
        "                gen_pos_to_del=list(set(gen_pos_to_del))\n",
        "                gen_pos_to_del.sort(reverse=True)\n",
        "                for i in gen_pos_to_del:\n",
        "                    del(gene_sorts[0][i])\n",
        "                #pos overlaps\n",
        "                for i in range(len(gene_sorts[0])-1): #fills the overlap list with the regions that are overlapping\n",
        "                    gbrp_obj.overlaps(i,gene_sorts[0],genedicts['lists']['pos_overlaps'])\n",
        "\n",
        "                #Neg gene filtering\n",
        "                gen_neg_to_del = []\n",
        "                gen_neg_prev_value = None\n",
        "                gen_neg_prev_value_index=None\n",
        "                for i in range(len(gene_sorts[1])): #deletes the bigger ones, keeping the smallest intron\n",
        "                    gen_neg_prev_value,gen_neg_prev_value_index=gbrp_obj.biggest(i, gene_sorts[1], gen_neg_to_del,gen_neg_prev_value,gen_neg_prev_value_index)\n",
        "                gen_neg_to_del=list(set(gen_neg_to_del))\n",
        "                gen_neg_to_del.sort(reverse=True)\n",
        "                for i in gen_neg_to_del:\n",
        "                    del(gene_sorts[1][i])\n",
        "                #neg overlaps\n",
        "                for i in range(len(gene_sorts[1])-1): #fills the overlap list with the regions that are overlapping\n",
        "                    gbrp_obj.overlaps(i,gene_sorts[1],genedicts['lists']['neg_overlaps'])\n",
        "\n",
        "                #Calculations and outputs\n",
        "                for i in gene_sorts[0]: #for positive genes\n",
        "                        sequence=gbrp_obj.seq('pos',i,seq)\n",
        "                        gbrp_obj.calculations (sequence,genedicts['counters']) #calculates all the output scores and saves the numbers in the relevent key,value in the counter dictionary\n",
        "                for i in gene_sorts[1]: #for negative genes\n",
        "                        sequence=gbrp_obj.seq('neg',i,seq)\n",
        "                        gbrp_obj.calculations (sequence,genedicts['counters']) #calculates all the output scores and saves the numbers in the relevent key,value in the counter dictionary\n",
        "                gen_cols=gbrp_obj.outputs(genedicts['counters'])\n",
        "\n",
        "                for i in genedicts['lists']['pos_overlaps']: #for positive gene overlaps\n",
        "                        sequence=gbrp_obj.seq('pos',i,seq)\n",
        "                        gbrp_obj.calculations (sequence,genedicts['overlap_counters']) #calculates all the output scores and saves the numbers in the relevent key,value in the counter dictionary\n",
        "                for i in genedicts['lists']['neg_overlaps']: #for negative gene overlaps\n",
        "                        sequence=gbrp_obj.seq('neg',i,seq)\n",
        "                        gbrp_obj.calculations (sequence,genedicts['overlap_counters']) #calculates all the output scores and saves the numbers in the relevent key,value in the counter dictionary\n",
        "                gen_over_cols=gbrp_obj.outputs(genedicts['overlap_counters'])\n",
        "\n",
        "                #####CDS####\n",
        "                cds_sorts=gbrp_obj.asc_sorter(cdsdicts['lists'])#sorts the list and removes duplicates\n",
        "                #pos exons filtering\n",
        "                pos_cds_to_del = []\n",
        "                pos_prev_value = None\n",
        "                pos_prev_value_index=None\n",
        "                for i in range(len(cds_sorts[0])): #deletes the bigger ones, keeping the smallest intron\n",
        "                    pos_prev_value,pos_prev_value_index=gbrp_obj.biggest(i, cds_sorts[0], pos_cds_to_del,pos_prev_value,pos_prev_value_index)\n",
        "                pos_cds_to_del=list(set(pos_cds_to_del))\n",
        "                pos_cds_to_del.sort(reverse=True)\n",
        "                for i in pos_cds_to_del:\n",
        "                    del(cds_sorts[0][i])\n",
        "                #pos overlaps\n",
        "                for i in range(len(cds_sorts[0])-1): #fills the overlap list with the regions that are overlapping\n",
        "                    gbrp_obj.overlaps(i,cds_sorts[0],cdsdicts['lists']['pos_overlaps'])\n",
        "\n",
        "                #Neg exons filtering\n",
        "                neg_cds_to_del = []\n",
        "                neg_prev_value = None\n",
        "                neg_prev_value_index=None\n",
        "                for i in range(len(cds_sorts[1])): #deletes the bigger ones, keeping the smallest intron\n",
        "                    neg_prev_value,neg_prev_value_index=gbrp_obj.biggest(i, cds_sorts[1], neg_cds_to_del,neg_prev_value,neg_prev_value_index)\n",
        "                neg_cds_to_del=list(set(neg_cds_to_del))\n",
        "                neg_cds_to_del.sort(reverse=True)\n",
        "                for i in neg_cds_to_del:\n",
        "                    del(cds_sorts[1][i])\n",
        "                #neg overlaps\n",
        "                for i in range(len(cds_sorts[1])-1): #fills the overlap list with the regions that are overlapping\n",
        "                    gbrp_obj.overlaps(i,cds_sorts[1],cdsdicts['lists']['neg_overlaps'])\n",
        "\n",
        "                #Calculations and outputs\n",
        "                for i in cds_sorts[0]: #for positive exons\n",
        "                        sequence=gbrp_obj.seq('pos',i,seq)\n",
        "                        gbrp_obj.calculations (sequence,cdsdicts['counters']) #calculates all the output scores and saves the numbers in the relevent key,value in the counter dictionary\n",
        "                        gbrp_obj.codon_count(sequence, cdsdicts['nucl_codon_counter']) #calculates the codon counts and saves them in the dict\n",
        "                for i in cds_sorts[1]: #for negative exons\n",
        "                        sequence=gbrp_obj.seq('neg',i,seq)\n",
        "                        gbrp_obj.calculations (sequence,cdsdicts['counters']) #calculates all the output scores and saves the numbers in the relevent key,value in the counter dictionary\n",
        "                        gbrp_obj.codon_count(sequence, cdsdicts['nucl_codon_counter'])\n",
        "                cds_cols=gbrp_obj.outputs(cdsdicts['counters'])\n",
        "                codon_cols=gbrp_obj.codon_outputs(cdsdicts['nucl_codon_counter'])\n",
        "                #OVERLAPS\n",
        "                for i in cdsdicts['lists']['pos_overlaps']: #for positive exon overlaps\n",
        "                        sequence=gbrp_obj.seq('pos',i,seq)\n",
        "                        gbrp_obj.calculations (sequence,cdsdicts['overlap_counters']) #calculates all the output scores and saves the numbers in the relevent key,value in the counter dictionary\n",
        "                        gbrp_obj.codon_count(sequence, cdsdicts['overlap_nucl_codon_counter'])\n",
        "                for i in cdsdicts['lists']['neg_overlaps']: #for negative exon overlaps\n",
        "                        sequence=gbrp_obj.seq('neg',i,seq)\n",
        "                        gbrp_obj.calculations (sequence,cdsdicts['overlap_counters']) #calculates all the output scores and saves the numbers in the relevent key,value in the counter dictionary\n",
        "                        gbrp_obj.codon_count(sequence, cdsdicts['overlap_nucl_codon_counter'])\n",
        "                cds_over_cols=gbrp_obj.outputs(cdsdicts['overlap_counters'])\n",
        "                cds_over_codon_cols=gbrp_obj.codon_outputs(cdsdicts['overlap_nucl_codon_counter'])\n",
        "\n",
        "\n",
        "                #####CDS INTRONS####\n",
        "                cdsintron_sorts=gbrp_obj.des_sorter(cds_introndicts['lists']) #sorts the list and removes duplicates\n",
        "                #deletes the bigger ones, keeping the smallest intron\n",
        "                pos_intron_to_del = []\n",
        "                pos_prev_value = None\n",
        "                pos_prev_value_index=None\n",
        "                for i in range(len(cdsintron_sorts[0])):\n",
        "                    pos_prev_value,pos_prev_value_index=gbrp_obj.smallest(i, cdsintron_sorts[0], pos_intron_to_del,pos_prev_value,pos_prev_value_index)\n",
        "                pos_intron_to_del=list(set(pos_intron_to_del))\n",
        "                pos_intron_to_del.sort(reverse=True)\n",
        "                for i in pos_intron_to_del:\n",
        "                    del(cdsintron_sorts[0][i])\n",
        "                #overlaps#\n",
        "                for i in range(len(cdsintron_sorts[0])-1): #fills the overlap list with the regions that are overlapping\n",
        "                    gbrp_obj.overlaps(i,cdsintron_sorts[0],cds_introndicts['lists']['pos_overlaps'])\n",
        "\n",
        "                #deletes the bigger ones, keeping the smallest intron\n",
        "                neg_intron_to_del = []\n",
        "                neg_prev_value = None\n",
        "                neg_prev_value_index=None\n",
        "                for i in range(len(cdsintron_sorts[1])):\n",
        "                    neg_prev_value,neg_prev_value_index=gbrp_obj.smallest(i, cdsintron_sorts[1], neg_intron_to_del,neg_prev_value,neg_prev_value_index)\n",
        "\n",
        "                neg_intron_to_del=list(set(neg_intron_to_del))\n",
        "                neg_intron_to_del.sort(reverse=True)\n",
        "                for i in neg_intron_to_del:\n",
        "                    del(cdsintron_sorts[1][i])\n",
        "                #overlaps\n",
        "                for i in range(len(cdsintron_sorts[1])-1): #fills the overlap list with the regions that are overlapping\n",
        "                    gbrp_obj.overlaps(i,cdsintron_sorts[1],cds_introndicts['lists']['neg_overlaps'])\n",
        "\n",
        "\n",
        "                for i in cdsintron_sorts[0]: #for positive introns\n",
        "                        sequence=gbrp_obj.seq('pos',i,seq)\n",
        "                        gbrp_obj.calculations (sequence,cds_introndicts['counters']) #calculates all the output scores and saves the numbers in the relevent key,value in the counter dictionary\n",
        "                for i in cdsintron_sorts[1]: #for negative introns\n",
        "                        sequence=gbrp_obj.seq('neg',i,seq)\n",
        "                        gbrp_obj.calculations (sequence,cds_introndicts['counters']) #calculates all the output scores and saves the numbers in the relevent key,value in the counter dictionary\n",
        "                CDSint_cols=gbrp_obj.outputs(cds_introndicts['counters'])\n",
        "\n",
        "                for i in cds_introndicts['lists']['pos_overlaps']: #for positive intron overlaps\n",
        "                        sequence=gbrp_obj.seq('pos',i,seq)\n",
        "                        gbrp_obj.calculations (sequence,cds_introndicts['overlap_counters']) #calculates all the output scores and saves the numbers in the relevent key,value in the counter dictionary\n",
        "                for i in cds_introndicts['lists']['neg_overlaps']: #for negative intron overlaps\n",
        "                        sequence=gbrp_obj.seq('neg',i,seq)\n",
        "                        gbrp_obj.calculations (sequence,cds_introndicts['overlap_counters']) #calculates all the output scores and saves the numbers in the relevent key,value in the counter dictionary\n",
        "\n",
        "                CDSint_over_cols=gbrp_obj.outputs(cds_introndicts['overlap_counters'])\n",
        "\n",
        "                #####ncRNA####\n",
        "                nc_sorts=gbrp_obj.asc_sorter(ncRNAdicts['lists'])#sorts the list and removes duplicates\n",
        "                #pos ncRNA filtering\n",
        "                nc_pos_to_del = []\n",
        "                nc_pos_prev_value = None\n",
        "                nc_pos_prev_value_index=None\n",
        "                for i in range(len(nc_sorts[0])): #deletes the smaller ones, keeping the biggest\n",
        "                    nc_pos_prev_value,nc_pos_prev_value_index=gbrp_obj.biggest(i, nc_sorts[0], nc_pos_to_del,nc_pos_prev_value,nc_pos_prev_value_index)\n",
        "                nc_pos_to_del=list(set(nc_pos_to_del))\n",
        "                nc_pos_to_del.sort(reverse=True)\n",
        "                for i in nc_pos_to_del:\n",
        "                    del(nc_sorts[0][i])\n",
        "                #pos overlaps\n",
        "                for i in range(len(nc_sorts[0])-1): #fills the overlap list with the regions that are overlapping\n",
        "                    gbrp_obj.overlaps(i,nc_sorts[0],ncRNAdicts['lists']['pos_overlaps'])\n",
        "\n",
        "                #Neg ncRNA filtering\n",
        "                nc_neg_to_del = []\n",
        "                nc_neg_prev_value = None\n",
        "                nc_neg_prev_value_index=None\n",
        "                for i in range(len(nc_sorts[1])): #deletes the smaller ones, keeping the biggest\n",
        "                    nc_neg_prev_value,nc_neg_prev_value_index=gbrp_obj.biggest(i, nc_sorts[1], nc_neg_to_del,nc_neg_prev_value,nc_neg_prev_value_index)\n",
        "                nc_neg_to_del=list(set(nc_neg_to_del))\n",
        "                nc_neg_to_del.sort(reverse=True)\n",
        "                for i in nc_neg_to_del:\n",
        "                    del(nc_sorts[1][i])\n",
        "                #neg overlaps\n",
        "                for i in range(len(nc_sorts[1])-1): #fills the overlap list with the regions that are overlapping\n",
        "                    gbrp_obj.overlaps(i,nc_sorts[1],ncRNAdicts['lists']['neg_overlaps'])\n",
        "\n",
        "                #Calculations and outputs\n",
        "                for i in nc_sorts[0]: #for positive ncRNA\n",
        "                        sequence=gbrp_obj.seq('pos',i,seq)\n",
        "                        gbrp_obj.calculations (sequence,ncRNAdicts['counters']) #calculates all the output scores and saves the numbers in the relevent key,value in the counter dictionary\n",
        "                for i in nc_sorts[1]: #for negative ncRNA\n",
        "                        sequence=gbrp_obj.seq('neg',i,seq)\n",
        "                        gbrp_obj.calculations (sequence,ncRNAdicts['counters']) #calculates all the output scores and saves the numbers in the relevent key,value in the counter dictionary\n",
        "                nc_cols=gbrp_obj.outputs(ncRNAdicts['counters'])\n",
        "\n",
        "                for i in ncRNAdicts['lists']['pos_overlaps']: #for positive ncRNA overlaps\n",
        "                        sequence=gbrp_obj.seq('pos',i,seq)\n",
        "                        gbrp_obj.calculations (sequence,ncRNAdicts['overlap_counters']) #calculates all the output scores and saves the numbers in the relevent key,value in the counter dictionary\n",
        "                for i in ncRNAdicts['lists']['neg_overlaps']: #for negative ncRNA overlaps\n",
        "                        sequence=gbrp_obj.seq('neg',i,seq)\n",
        "                        gbrp_obj.calculations (sequence,ncRNAdicts['overlap_counters']) #calculates all the output scores and saves the numbers in the relevent key,value in the counter dictionary\n",
        "                nc_over_cols=gbrp_obj.outputs(ncRNAdicts['overlap_counters'])\n",
        "\n",
        "                #####ncRNA INTRONS####\n",
        "                ncintron_sorts=gbrp_obj.des_sorter(nc_introndicts['lists']) #sorts the list and removes duplicates\n",
        "                #pos ncRNA intron filtering\n",
        "                ncIntro_pos_to_del = []\n",
        "                ncIntro_pos_prev_value = None\n",
        "                ncIntro_pos_prev_value_index=None\n",
        "                for i in range(len(ncintron_sorts[0])): #deletes the bigger ones, keeping the smallest intron\n",
        "                    ncIntro_pos_prev_value,ncIntro_pos_prev_value_index=gbrp_obj.smallest(i, ncintron_sorts[0], ncIntro_pos_to_del,ncIntro_pos_prev_value,ncIntro_pos_prev_value_index)\n",
        "                ncIntro_pos_to_del=list(set(ncIntro_pos_to_del))\n",
        "                ncIntro_pos_to_del.sort(reverse=True)\n",
        "                for i in ncIntro_pos_to_del:\n",
        "                    del(ncintron_sorts[0][i])\n",
        "                #overlaps#\n",
        "                for i in range(len(ncintron_sorts[0])-1): #fills the overlap list with the regions that are overlapping\n",
        "                    gbrp_obj.overlaps(i,ncintron_sorts[0],nc_introndicts['lists']['pos_overlaps'])\n",
        "\n",
        "                #neg ncRNA intron filtering\n",
        "                ncIntro_neg_to_del = []\n",
        "                ncIntro_neg_prev_value = None\n",
        "                ncIntro_neg_prev_value_index=None\n",
        "                for i in range(len(ncintron_sorts[1])): #deletes the bigger ones, keeping the smallest intron\n",
        "                    ncIntro_neg_prev_value,ncIntro_neg_prev_value_index=gbrp_obj.smallest(i, ncintron_sorts[1], ncIntro_neg_to_del,ncIntro_neg_prev_value,ncIntro_neg_prev_value_index)\n",
        "                ncIntro_neg_to_del=list(set(ncIntro_neg_to_del))\n",
        "                ncIntro_neg_to_del.sort(reverse=True)\n",
        "                for i in ncIntro_neg_to_del:\n",
        "                    del(ncintron_sorts[1][i])\n",
        "                #overlaps\n",
        "                for i in range(len(ncintron_sorts[1])-1): #fills the overlap list with the regions that are overlapping\n",
        "                    gbrp_obj.overlaps(i,ncintron_sorts[1],nc_introndicts['lists']['neg_overlaps'])\n",
        "\n",
        "                for i in ncintron_sorts[0]: #for positive introns\n",
        "                        sequence=gbrp_obj.seq('pos',i,seq)\n",
        "                        gbrp_obj.calculations (sequence,nc_introndicts['counters']) #calculates all the output scores and saves the numbers in the relevent key,value in the counter dictionary\n",
        "                for i in ncintron_sorts[1]: #for negative introns\n",
        "                        sequence=gbrp_obj.seq('neg',i,seq)\n",
        "                        gbrp_obj.calculations (sequence,nc_introndicts['counters']) #calculates all the output scores and saves the numbers in the relevent key,value in the counter dictionary\n",
        "                ncint_cols=gbrp_obj.outputs(nc_introndicts['counters'])\n",
        "\n",
        "                for i in nc_introndicts['lists']['pos_overlaps']: #for positive intron overlaps\n",
        "                        sequence=gbrp_obj.seq('pos',i,seq)\n",
        "                        gbrp_obj.calculations (sequence,nc_introndicts['overlap_counters']) #calculates all the output scores and saves the numbers in the relevent key,value in the counter dictionary\n",
        "                for i in nc_introndicts['lists']['neg_overlaps']: #for negative intron overlaps\n",
        "                        sequence=gbrp_obj.seq('neg',i,seq)\n",
        "                        gbrp_obj.calculations (sequence,nc_introndicts['overlap_counters']) #calculates all the output scores and saves the numbers in the relevent key,value in the counter dictionary\n",
        "\n",
        "                ncint_over_cols=gbrp_obj.outputs(nc_introndicts['overlap_counters'])\n",
        "\n",
        "                #####tRNA####\n",
        "                trna_sorts=gbrp_obj.asc_sorter(tRNAdicts['lists'])#sorts the list and removes duplicates\n",
        "                #pos tRNA filtering\n",
        "                tr_pos_to_del = []\n",
        "                tr_pos_prev_value = None\n",
        "                tr_pos_prev_value_index=None\n",
        "                for i in range(len(trna_sorts[0])): #deletes the smaller ones, keeping the biggest\n",
        "                    tr_pos_prev_value,tr_pos_prev_value_index=gbrp_obj.biggest(i, trna_sorts[0], tr_pos_to_del,tr_pos_prev_value,tr_pos_prev_value_index)\n",
        "                tr_pos_to_del=list(set(tr_pos_to_del))\n",
        "                tr_pos_to_del.sort(reverse=True)\n",
        "                for i in tr_pos_to_del:\n",
        "                    del(trna_sorts[0][i])\n",
        "                #pos overlaps\n",
        "                for i in range(len(trna_sorts[0])-1): #fills the overlap list with the regions that are overlapping\n",
        "                    gbrp_obj.overlaps(i,trna_sorts[0],tRNAdicts['lists']['pos_overlaps'])\n",
        "\n",
        "                #Neg tRNA filtering\n",
        "                tr_neg_to_del = []\n",
        "                tr_neg_prev_value = None\n",
        "                tr_neg_prev_value_index=None\n",
        "                for i in range(len(trna_sorts[1])): #deletes the smaller ones, keeping the biggest\n",
        "                    tr_neg_prev_value,tr_neg_prev_value_index=gbrp_obj.biggest(i, trna_sorts[1], tr_neg_to_del,tr_neg_prev_value,tr_neg_prev_value_index)\n",
        "                tr_neg_to_del=list(set(tr_neg_to_del))\n",
        "                tr_neg_to_del.sort(reverse=True)\n",
        "                for i in tr_neg_to_del:\n",
        "                    del(trna_sorts[1][i])\n",
        "                #neg overlaps\n",
        "                for i in range(len(trna_sorts[1])-1): #fills the overlap list with the regions that are overlapping\n",
        "                    gbrp_obj.overlaps(i,trna_sorts[1],tRNAdicts['lists']['neg_overlaps'])\n",
        "\n",
        "                #Calculations and outputs\n",
        "                for i in trna_sorts[0]: #for positive tRNA\n",
        "                        sequence=gbrp_obj.seq('pos',i,seq)\n",
        "                        gbrp_obj.calculations (sequence,tRNAdicts['counters']) #calculates all the output scores and saves the numbers in the relevent key,value in the counter dictionary\n",
        "                for i in trna_sorts[1]: #for negative tRNA\n",
        "                        sequence=gbrp_obj.seq('neg',i,seq)\n",
        "                        gbrp_obj.calculations (sequence,tRNAdicts['counters']) #calculates all the output scores and saves the numbers in the relevent key,value in the counter dictionary\n",
        "                tr_cols=gbrp_obj.outputs(tRNAdicts['counters'])\n",
        "\n",
        "                for i in tRNAdicts['lists']['pos_overlaps']: #for positive tRNA overlaps\n",
        "                        sequence=gbrp_obj.seq('pos',i,seq)\n",
        "                        gbrp_obj.calculations (sequence,tRNAdicts['overlap_counters']) #calculates all the output scores and saves the numbers in the relevent key,value in the counter dictionary\n",
        "                for i in tRNAdicts['lists']['neg_overlaps']: #for negative tRNA overlaps\n",
        "                        sequence=gbrp_obj.seq('neg',i,seq)\n",
        "                        gbrp_obj.calculations (sequence,tRNAdicts['overlap_counters']) #calculates all the output scores and saves the numbers in the relevent key,value in the counter dictionary\n",
        "                tr_over_cols=gbrp_obj.outputs(tRNAdicts['overlap_counters'])\n",
        "\n",
        "\n",
        "                #####rRNA####\n",
        "                rrna_sorts=gbrp_obj.asc_sorter(rRNAdicts['lists'])#sorts the list and removes duplicates\n",
        "                #pos rRNA filtering\n",
        "                rr_pos_to_del = []\n",
        "                rr_pos_prev_value = None\n",
        "                rr_pos_prev_value_index=None\n",
        "                for i in range(len(rrna_sorts[0])): #deletes the smaller ones, keeping the biggest\n",
        "                    rr_pos_prev_value,rr_pos_prev_value_index=gbrp_obj.biggest(i, rrna_sorts[0], rr_pos_to_del,rr_pos_prev_value,rr_pos_prev_value_index)\n",
        "                rr_pos_to_del=list(set(rr_pos_to_del))\n",
        "                rr_pos_to_del.sort(reverse=True)\n",
        "                for i in rr_pos_to_del:\n",
        "                    del(rrna_sorts[0][i])\n",
        "                #pos overlaps\n",
        "                for i in range(len(rrna_sorts[0])-1): #fills the overlap list with the regions that are overlapping\n",
        "                    gbrp_obj.overlaps(i,rrna_sorts[0],rRNAdicts['lists']['pos_overlaps'])\n",
        "\n",
        "                #Neg rRNA filtering\n",
        "                rr_neg_to_del = []\n",
        "                rr_neg_prev_value = None\n",
        "                rr_neg_prev_value_index=None\n",
        "                for i in range(len(rrna_sorts[1])): #deletes the smaller ones, keeping the biggest\n",
        "                    rr_neg_prev_value,rr_neg_prev_value_index=gbrp_obj.biggest(i, rrna_sorts[1], rr_neg_to_del,rr_neg_prev_value,rr_neg_prev_value_index)\n",
        "                rr_neg_to_del=list(set(rr_neg_to_del))\n",
        "                rr_neg_to_del.sort(reverse=True)\n",
        "                for i in rr_neg_to_del:\n",
        "                    del(rrna_sorts[1][i])\n",
        "                #neg overlaps\n",
        "                for i in range(len(rrna_sorts[1])-1): #fills the overlap list with the regions that are overlapping\n",
        "                    gbrp_obj.overlaps(i,rrna_sorts[1],rRNAdicts['lists']['neg_overlaps'])\n",
        "\n",
        "                #Calculations and outputs\n",
        "                for i in rrna_sorts[0]: #for positive rRNA\n",
        "                        sequence=gbrp_obj.seq('pos',i,seq)\n",
        "                        gbrp_obj.calculations (sequence,rRNAdicts['counters']) #calculates all the output scores and saves the numbers in the relevent key,value in the counter dictionary\n",
        "                for i in rrna_sorts[1]: #for negative rRNA\n",
        "                        sequence=gbrp_obj.seq('neg',i,seq)\n",
        "                        gbrp_obj.calculations (sequence,rRNAdicts['counters']) #calculates all the output scores and saves the numbers in the relevent key,value in the counter dictionary\n",
        "                rr_cols=gbrp_obj.outputs(rRNAdicts['counters'])\n",
        "\n",
        "                for i in rRNAdicts['lists']['pos_overlaps']: #for positive rRNA overlaps\n",
        "                        sequence=gbrp_obj.seq('pos',i,seq)\n",
        "                        gbrp_obj.calculations (sequence,rRNAdicts['overlap_counters']) #calculates all the output scores and saves the numbers in the relevent key,value in the counter dictionary\n",
        "                for i in rRNAdicts['lists']['neg_overlaps']: #for negative rRNA overlaps\n",
        "                        sequence=gbrp_obj.seq('neg',i,seq)\n",
        "                        gbrp_obj.calculations (sequence,rRNAdicts['overlap_counters']) #calculates all the output scores and saves the numbers in the relevent key,value in the counter dictionary\n",
        "                rr_over_cols=gbrp_obj.outputs(rRNAdicts['overlap_counters'])\n",
        "\n",
        "                #genomewide counts\n",
        "                for key in genome.keys():\n",
        "                    element_dict = globals()[key]['counters']\n",
        "\n",
        "                    if key=='chromodicts':\n",
        "                        for small_key in element_dict.keys():\n",
        "                            genome[key]['counters'][small_key]+=element_dict[small_key]\n",
        "\n",
        "                    elif key=='cdsdicts':\n",
        "                        codon_dict=cdsdicts['nucl_codon_counter']\n",
        "                        for codon_key in codon_dict.keys():\n",
        "                            genome[key]['nucl_codon_counter'][codon_key]+=codon_dict[codon_key]\n",
        "\n",
        "                        overlap_element_dict = globals()[key]['overlap_counters']\n",
        "                        for small_key in element_dict.keys():\n",
        "                            genome[key]['counters'][small_key]+=element_dict[small_key]\n",
        "                            genome[key]['overlap_counters'][small_key]+=overlap_element_dict[small_key]\n",
        "\n",
        "\n",
        "                    else:\n",
        "                        overlap_element_dict = globals()[key]['overlap_counters']\n",
        "                        for small_key in element_dict.keys():\n",
        "                            genome[key]['counters'][small_key]+=element_dict[small_key]\n",
        "                            genome[key]['overlap_counters'][small_key]+=overlap_element_dict[small_key]\n",
        "\n",
        "\n",
        "\n",
        "                if analysis=='c':\n",
        "                    ##########FINAL########\n",
        "                    outputfile.writerow([category,organism,taxa,assembly,col1,version,col2,\n",
        "                                         chromo_cols[0],chromo_cols[1],chromo_cols[2],chromo_cols[3],chromo_cols[4],\n",
        "                                         chromo_cols[5],chromo_cols[6],chromo_cols[7],chromo_cols[8],chromo_cols[9],chromo_cols[10],chromo_cols[11],\n",
        "                                         chromo_cols[12],chromo_cols[13],chromo_cols[14],chromo_cols[15],gen_counts[0],gen_counts[1],gen_counts[2],gen_cols[0],gen_cols[1],gen_cols[2],gen_cols[3],gen_cols[4],gen_cols[5],gen_cols[6],gen_cols[7],\n",
        "                                          gen_cols[8],gen_cols[9],gen_cols[10],gen_cols[11],gen_cols[12],gen_cols[13],gen_cols[14],gen_cols[15],\n",
        "                                          gen_over_cols[5],cds_counts[0],cds_counts[1],cds_counts[2],cds_cols[0],cds_cols[1],cds_cols[2],cds_cols[3],cds_cols[4],cds_cols[5],\n",
        "                                          cds_cols[6],cds_cols[7],cds_cols[8],cds_cols[9],cds_cols[10],cds_cols[11],cds_cols[12],cds_cols[13],\n",
        "                                          cds_cols[14],cds_cols[15],cds_over_cols[5],CDSint_cols[0],CDSint_cols[1],CDSint_cols[2],\n",
        "                                          CDSint_cols[3],CDSint_cols[4],CDSint_cols[5],CDSint_cols[6],CDSint_cols[7],CDSint_cols[8],CDSint_cols[9],\n",
        "                                          CDSint_cols[10],CDSint_cols[11],CDSint_cols[12],CDSint_cols[13],CDSint_cols[14],CDSint_cols[15],\n",
        "                                          CDSint_over_cols[5],nc_counts[0],nc_counts[1],nc_counts[2],nc_cols[0],nc_cols[1],nc_cols[2],nc_cols[3],nc_cols[4],nc_cols[5],nc_cols[6],\n",
        "                                          nc_cols[7],nc_cols[8],nc_cols[9],nc_cols[10],nc_cols[11],nc_cols[12],nc_cols[13],nc_cols[14],nc_cols[15],\n",
        "                                          nc_over_cols[5],ncint_cols[0],ncint_cols[1],ncint_cols[2],ncint_cols[3],ncint_cols[4],ncint_cols[5],\n",
        "                                          ncint_cols[6],ncint_cols[7],ncint_cols[8],ncint_cols[9],ncint_cols[10],ncint_cols[11],ncint_cols[12],\n",
        "                                          ncint_cols[13],ncint_cols[14],ncint_cols[15],ncint_over_cols[5],tr_counts[0],tr_counts[1],tr_counts[2],tr_cols[0],tr_cols[1],tr_cols[2],\n",
        "                                          tr_cols[3],tr_cols[4],tr_cols[5],tr_cols[6],tr_cols[7],tr_cols[8],tr_cols[9],tr_cols[10],tr_cols[11],tr_cols[12],\n",
        "                                          tr_cols[13],tr_cols[14],tr_cols[15],tr_over_cols[5],rr_counts[0],rr_counts[1],rr_counts[2],rr_cols[0],rr_cols[1],rr_cols[2],rr_cols[3],rr_cols[4],\n",
        "                                          rr_cols[5],rr_cols[6],rr_cols[7],rr_cols[8],rr_cols[9],rr_cols[10],rr_cols[11],rr_cols[12],rr_cols[13],rr_cols[14],\n",
        "                                          rr_cols[15],rr_over_cols[5],codon_cols[0], codon_cols[1], codon_cols[2],\n",
        "                                          codon_cols[3], codon_cols[4], codon_cols[5],codon_cols[6], codon_cols[7], codon_cols[8], codon_cols[9],\n",
        "                                          codon_cols[10], codon_cols[11], codon_cols[12], codon_cols[13],codon_cols[14], codon_cols[15], codon_cols[16],\n",
        "                                          codon_cols[17], codon_cols[18], codon_cols[19], codon_cols[20], codon_cols[21],codon_cols[22], codon_cols[23],\n",
        "                                          codon_cols[24], codon_cols[25], codon_cols[26], codon_cols[27], codon_cols[28], codon_cols[29],codon_cols[30],\n",
        "                                          codon_cols[31], codon_cols[32], codon_cols[33], codon_cols[34], codon_cols[35], codon_cols[36], codon_cols[37],\n",
        "                                          codon_cols[38], codon_cols[39], codon_cols[40], codon_cols[41], codon_cols[42], codon_cols[43], codon_cols[44],\n",
        "                                          codon_cols[45],codon_cols[46], codon_cols[47], codon_cols[48], codon_cols[49], codon_cols[50], codon_cols[51],\n",
        "                                          codon_cols[52], codon_cols[53],codon_cols[54], codon_cols[55], codon_cols[56], codon_cols[57], codon_cols[58],\n",
        "                                          codon_cols[59], codon_cols[60], codon_cols[61],codon_cols[62], codon_cols[63]])\n",
        "\n",
        "                    print(f'\\nCompleted:{col2}')\n",
        "\n",
        "\n",
        "            locus_counter=locus_counter+1\n",
        "\n",
        "        if analysis=='g' and analysed_chromo!=0:\n",
        "            genome_gen_counts=gbrp_obj.count_cols(genome['genedicts'])\n",
        "            genome_cds_counts=gbrp_obj.count_cols(genome['cdsdicts'])\n",
        "            genome_nc_counts=gbrp_obj.count_cols(genome['ncRNAdicts'])\n",
        "            genome_tr_counts=gbrp_obj.count_cols(genome['tRNAdicts'])\n",
        "            genome_rr_counts=gbrp_obj.count_cols(genome['rRNAdicts'])\n",
        "\n",
        "            genome_chromo_cols=gbrp_obj.outputs(genome['chromodicts']['counters'])\n",
        "            genome_gen_cols=gbrp_obj.outputs(genome['genedicts']['counters'])\n",
        "            genome_cds_cols=gbrp_obj.outputs(genome['cdsdicts']['counters'])\n",
        "            genome_CDSint_cols=gbrp_obj.outputs(genome['cds_introndicts']['counters'])\n",
        "            genome_nc_cols=gbrp_obj.outputs(genome['ncRNAdicts']['counters'])\n",
        "            genome_ncint_cols=gbrp_obj.outputs(genome['nc_introndicts']['counters'])\n",
        "            genome_tr_cols=gbrp_obj.outputs(genome['tRNAdicts']['counters'])\n",
        "            genome_rr_cols=gbrp_obj.outputs(genome['rRNAdicts']['counters'])\n",
        "\n",
        "            genome_gen_over_cols=gbrp_obj.outputs(genome['genedicts']['overlap_counters'])\n",
        "            genome_cds_over_cols=gbrp_obj.outputs(genome['cdsdicts']['overlap_counters'])\n",
        "            genome_CDSint_over_cols=gbrp_obj.outputs(genome['cds_introndicts']['overlap_counters'])\n",
        "            genome_nc_over_cols=gbrp_obj.outputs(genome['ncRNAdicts']['overlap_counters'])\n",
        "            genome_ncint_over_cols=gbrp_obj.outputs(genome['nc_introndicts']['overlap_counters'])\n",
        "            genome_tr_over_cols=gbrp_obj.outputs(genome['tRNAdicts']['overlap_counters'])\n",
        "            genome_rr_over_cols=gbrp_obj.outputs(genome['rRNAdicts']['overlap_counters'])\n",
        "\n",
        "            genome_codon_cols=gbrp_obj.codon_outputs(genome['cdsdicts']['nucl_codon_counter'])\n",
        "\n",
        "            outputfile.writerow([category,organism,taxa,assembly,'NA','NA','Whole Genome',\n",
        "                                 genome_chromo_cols[0],genome_chromo_cols[1],genome_chromo_cols[2],genome_chromo_cols[3],genome_chromo_cols[4],\n",
        "                                 genome_chromo_cols[5],genome_chromo_cols[6],genome_chromo_cols[7],genome_chromo_cols[8],genome_chromo_cols[9],genome_chromo_cols[10],genome_chromo_cols[11],\n",
        "                                 genome_chromo_cols[12],genome_chromo_cols[13],genome_chromo_cols[14],genome_chromo_cols[15],genome_gen_counts[0],genome_gen_counts[1],genome_gen_counts[2],\n",
        "                                 genome_gen_cols[0],genome_gen_cols[1],genome_gen_cols[2],genome_gen_cols[3],genome_gen_cols[4],genome_gen_cols[5],genome_gen_cols[6],genome_gen_cols[7],\n",
        "                                  genome_gen_cols[8],genome_gen_cols[9],genome_gen_cols[10],genome_gen_cols[11],genome_gen_cols[12],genome_gen_cols[13],genome_gen_cols[14],genome_gen_cols[15],\n",
        "                                  genome_gen_over_cols[5],genome_cds_counts[0],genome_cds_counts[1],genome_cds_counts[2],genome_cds_cols[0],genome_cds_cols[1],genome_cds_cols[2],genome_cds_cols[3],genome_cds_cols[4],genome_cds_cols[5],\n",
        "                                  genome_cds_cols[6],genome_cds_cols[7],genome_cds_cols[8],genome_cds_cols[9],genome_cds_cols[10],genome_cds_cols[11],genome_cds_cols[12],genome_cds_cols[13],\n",
        "                                  genome_cds_cols[14],genome_cds_cols[15],genome_cds_over_cols[5],genome_CDSint_cols[0],genome_CDSint_cols[1],genome_CDSint_cols[2],\n",
        "                                  genome_CDSint_cols[3],genome_CDSint_cols[4],genome_CDSint_cols[5],genome_CDSint_cols[6],genome_CDSint_cols[7],genome_CDSint_cols[8],genome_CDSint_cols[9],\n",
        "                                  genome_CDSint_cols[10],genome_CDSint_cols[11],genome_CDSint_cols[12],genome_CDSint_cols[13],genome_CDSint_cols[14],genome_CDSint_cols[15],\n",
        "                                  genome_CDSint_over_cols[5],genome_nc_counts[0],genome_nc_counts[1],genome_nc_counts[2],genome_nc_cols[0],genome_nc_cols[1],genome_nc_cols[2],genome_nc_cols[3],genome_nc_cols[4],genome_nc_cols[5],genome_nc_cols[6],\n",
        "                                  genome_nc_cols[7],genome_nc_cols[8],genome_nc_cols[9],genome_nc_cols[10],genome_nc_cols[11],genome_nc_cols[12],genome_nc_cols[13],genome_nc_cols[14],genome_nc_cols[15],\n",
        "                                  genome_nc_over_cols[5],genome_ncint_cols[0],genome_ncint_cols[1],genome_ncint_cols[2],genome_ncint_cols[3],genome_ncint_cols[4],genome_ncint_cols[5],\n",
        "                                  genome_ncint_cols[6],genome_ncint_cols[7],genome_ncint_cols[8],genome_ncint_cols[9],genome_ncint_cols[10],genome_ncint_cols[11],genome_ncint_cols[12],\n",
        "                                  genome_ncint_cols[13],genome_ncint_cols[14],genome_ncint_cols[15],genome_ncint_over_cols[5],genome_tr_counts[0],genome_tr_counts[1],genome_tr_counts[2],genome_tr_cols[0],genome_tr_cols[1],genome_tr_cols[2],\n",
        "                                  genome_tr_cols[3],genome_tr_cols[4],genome_tr_cols[5],genome_tr_cols[6],genome_tr_cols[7],genome_tr_cols[8],genome_tr_cols[9],genome_tr_cols[10],genome_tr_cols[11],genome_tr_cols[12],\n",
        "                                  genome_tr_cols[13],genome_tr_cols[14],genome_tr_cols[15],genome_tr_over_cols[5],genome_rr_counts[0],genome_rr_counts[1],genome_rr_counts[2],genome_rr_cols[0],genome_rr_cols[1],genome_rr_cols[2],genome_rr_cols[3],genome_rr_cols[4],\n",
        "                                  genome_rr_cols[5],genome_rr_cols[6],genome_rr_cols[7],genome_rr_cols[8],genome_rr_cols[9],genome_rr_cols[10],genome_rr_cols[11],genome_rr_cols[12],genome_rr_cols[13],genome_rr_cols[14],\n",
        "                                  genome_rr_cols[15],genome_rr_over_cols[5],genome_codon_cols[0],genome_codon_cols[1],genome_codon_cols[2],\n",
        "                                  genome_codon_cols[3], genome_codon_cols[4],genome_codon_cols[5],genome_codon_cols[6], genome_codon_cols[7], genome_codon_cols[8], genome_codon_cols[9],\n",
        "                                  genome_codon_cols[10], genome_codon_cols[11], genome_codon_cols[12], genome_codon_cols[13],genome_codon_cols[14], genome_codon_cols[15], genome_codon_cols[16],\n",
        "                                  genome_codon_cols[17], genome_codon_cols[18], genome_codon_cols[19], genome_codon_cols[20], genome_codon_cols[21],genome_codon_cols[22], genome_codon_cols[23],\n",
        "                                  genome_codon_cols[24], genome_codon_cols[25], genome_codon_cols[26], genome_codon_cols[27], genome_codon_cols[28], genome_codon_cols[29],genome_codon_cols[30],\n",
        "                                  genome_codon_cols[31], genome_codon_cols[32], genome_codon_cols[33], genome_codon_cols[34], genome_codon_cols[35], genome_codon_cols[36], genome_codon_cols[37],\n",
        "                                  genome_codon_cols[38], genome_codon_cols[39], genome_codon_cols[40], genome_codon_cols[41], genome_codon_cols[42], genome_codon_cols[43], genome_codon_cols[44],\n",
        "                                  genome_codon_cols[45],genome_codon_cols[46], genome_codon_cols[47], genome_codon_cols[48], genome_codon_cols[49], genome_codon_cols[50], genome_codon_cols[51],\n",
        "                                  genome_codon_cols[52], genome_codon_cols[53],genome_codon_cols[54], genome_codon_cols[55], genome_codon_cols[56], genome_codon_cols[57], genome_codon_cols[58],\n",
        "                                  genome_codon_cols[59], genome_codon_cols[60], genome_codon_cols[61],genome_codon_cols[62], genome_codon_cols[63]])\n",
        "\n",
        "            print(\"\\nAnalysis completed at whole genome level\")\n",
        "\n",
        "        if analysed_chromo==0:\n",
        "                print(\"\\nUnfortunately the input file does not contain any complete chromosomal/mitochondrial or plasmid sequences to analyse.There won't be any data in the output file\\nPlease re try with another version or another organism.\")\n",
        "\n",
        "        print (\"\\nSKIPPED\",skipped, \"loci due to being either\",\"/\".join(skiplocus) )\n",
        "\n",
        "\n",
        "    print('\\nAnalysis Finished\\nRun Time :',datetime.now() - startTime)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "za28zSVANwGw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6305f6c-8e95-445a-afe1-627d4cbb5a72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "please write the complete name of the input file:/content/GCF_000006945.2_ASM694v2_genomic.gbff.txt\n",
            "please write a name for the output file heremy\n",
            "Please input c for chromosome level analysis and g for whole genome analysis c\n",
            "\n",
            "GBRAP Analysis started for Salmonella_enterica_subsp._enterica_serovar_Typhimurium_str._LT2\n",
            "--\n",
            "\n",
            "Completed:Salmonella enterica subsp. enterica serovar Typhimurium str. LT2; complete genome.\n",
            "\n",
            "Completed:Salmonella enterica subsp. enterica serovar Typhimurium str. LT2 plasmid pSLT; complete sequence.\n",
            "\n",
            "SKIPPED 0 loci due to being either scaffold/unlocalized/contig/unplaced/patch/unknown\n",
            "\n",
            "Analysis Finished\n",
            "Run Time : 0:00:48.637905\n"
          ]
        }
      ]
    }
  ]
}