{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae171f0c-783a-47e7-b5fd-34bd9aa568c4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    " # Machine learning methods for the analysis of bacterial genomes: classification using Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14636741-d57e-4920-b893-a377a1cf3526",
   "metadata": {},
   "source": [
    "We provide here a workflow for machine learning (ML) classification of binary outcomes (e.g. healthy/sick, presence/absence, yes/no) based on a set of features or predictors (e.g. metadata) using random forest. \n",
    "\n",
    "To test this workflow we used a random subset (subset.csv) of the dataset utilized in Bobbo et al. (2024; https://doi.org/10.1186/s12864-024-10832-y), a study which aimed to apply ML algorithms to replicate the accurate classification of archaea and bacteria and to extract the relevant genomic features that drive their classification. Archaea and Bacteria are distinct domains of life that are adapted to a variety of ecological niches. Several genome-based methods have been developed for their accurate classification, yet many aspects of the specific genomic features that determine these differences are not fully understood. In Bobbo et al. (2024), we used publicly available whole-genome sequences from bacteria and archaea. From these, a set of genomic features (nucleotide frequencies and proportions, coding sequences (CDS), non-coding, ribosomal and transfer RNA genes (ncRNA, rRNA, tRNA), Chargaff’s, topological entropy and Shannon’s entropy scores) was extracted using GBRAP tool and used as input data to develop ML models for the classification of archaea and bacteria.\n",
    "For this workflow, the input dataset should include, in order: binary Outcome (e.g., Archaea/Bacteria), ID (e.g., sample ID), features/predictors. A total of 363 records (109 Archaea and 254 Bacteria) and 79 genomic features (numerical variables) were considered in \"subset.csv\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbce6c6c-3f05-48fb-bef0-9ad76b779717",
   "metadata": {},
   "source": [
    "## Install libraries\n",
    "Install required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90fedfb-dd27-4fa2-aa9d-7816c9931e02",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "install.packages('vip') \n",
    "install.packages('randomForest') \n",
    "#install.packages('ggplot2') already installed\n",
    "#install.packages('tidyverse') already installed\n",
    "#install.packages('data.table') already installed\n",
    "install.packages('tidymodels') \n",
    "install.packages('themis') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862e6f35-296f-4494-a700-9d177be48ee4",
   "metadata": {},
   "source": [
    "## Load libraries\n",
    "Load required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22e8efb6-ad75-4977-9185-20941436ec7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(\"vip\")\n",
    "library(\"randomForest\")\n",
    "library(\"ggplot2\")\n",
    "library(\"tidyverse\")\n",
    "library(\"data.table\")\n",
    "library(\"tidymodels\")\n",
    "library(\"themis\")  # for step_upsample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead0c55d-31ac-401b-88aa-f9a13b49b2d6",
   "metadata": {},
   "source": [
    "## Parameters setting\n",
    "The parameters that the user have to set prior to the analysis are listed below:\n",
    "\n",
    "- input_file: input dataset \n",
    "- split_ratio: dataset train/test split proportion (e.g., 80:20 = 0.80, 70:30 = 0.70);\n",
    "- k_folds: number of folds in (repeated) K-fold crossvalidation  (e.g., 3,5,10);\n",
    "- nrepeats_cv: number of k-fold crossvalidation repeats (e.g., 10,100,1000; 1 is recommended as a first test) during model training;\n",
    "\n",
    "The ML analysis is performed using the R Tidymodels package and detailed information can be found at https://www.tidymodels.org/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0e9b66-74df-409d-af4e-292bb0f413c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"subset.csv\" \n",
    "split_ratio = 0.80 \n",
    "k_folds = 10 \n",
    "nrepeats_cv = 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b29437-0d5a-486b-bb3b-35e072dfd33f",
   "metadata": {},
   "source": [
    "## Import dataset\n",
    "- Import dataset : specify \".\" for decimals; \".\", \"-\", \"NA\" will be considered as missing values; convert character columns to factors\n",
    "- Check dataset dimension (number of records and columns)\n",
    "- Visualize first six records\n",
    "- Check structure of the dataset : binary outcome and ID should be considered as factors, features can be all numeric (e.g, height, weight), all factors (e.g., sex) or both.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73500c9a-f4bd-4d66-867d-f5c53abb620b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset <- fread(input_file, dec = \".\", na.strings = c(\".\", \"-\", \"NA\"), stringsAsFactors = TRUE)\n",
    "dim(dataset)\n",
    "head(dataset)\n",
    "str(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e6443f-fb31-4b49-9868-8b0712edf64c",
   "metadata": {},
   "source": [
    "## Dataset preprocessing : missing values\n",
    "This workflow works only with complete datasets (no missing values), so sanity check before running the analysis in required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a027c8-b00c-4cd6-adf5-17a37296335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "\n",
    "if (sum(is.na(dataset)) == 0) {\n",
    "  print(\"No missing data in the dataset: OK! Go to 'Dataset preprocessing : descriptive statistics'\")\n",
    "} else {\n",
    "  print(\"Missing data in the dataset: please remove them! Go to 'Keep only complete records' cell\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054c9918-8945-436b-93bf-1ec3c6f4d63e",
   "metadata": {},
   "source": [
    "If there are no missing values, proceed with the analysis. \n",
    "If missing values are detected after the sanity check, please remove them with the appropriate code using complete.cases()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e58a727-0fde-4006-91d0-63c755e72aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only complete records and check dataset dimension\n",
    "\n",
    "dataset <- dataset[complete.cases(dataset), ]\n",
    "dim(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79bcb21-0c1d-4ae7-ac5c-2fa14dad97dd",
   "metadata": {},
   "source": [
    "## Dataset preprocessing : descriptive statistics\n",
    "Descriptive statistics (frequencies or distribution) of all variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134d546b-3988-4bf2-906f-4f4d3cc8bf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8ea713-d4a0-431d-a8ef-1b57ea2004cc",
   "metadata": {},
   "source": [
    "## Machine learning analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a459e32-5f92-4c0b-a046-d62e6761e0ba",
   "metadata": {},
   "source": [
    "### Training/test split\n",
    "\n",
    "The dataset will be splitted into a subset used to train and validate the model, and a subset that will be used to test the model's performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729cc61b-76cc-4718-9451-0a9becbd799b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter \"split_ratio\" will be applied to choose the ratio used to split tha dataset by outcome (e.g., 80:20, 70:30)\n",
    "\n",
    "rf_dt <- select(dataset, -c(ID))\n",
    "rf_split <- initial_split(rf_dt, strata = Outcome, prop = split_ratio)\n",
    "rf_train <- training(rf_split)\n",
    "rf_test <- testing(rf_split)\n",
    "\n",
    "# Sanity check on outcome frequencies in train and test sets\n",
    "\n",
    "rf_train %>% count(Outcome) |> print()\n",
    "rf_test %>% count(Outcome) |> print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d50b3c-1fe1-4c10-a51d-fc2c740f25eb",
   "metadata": {},
   "source": [
    "## Preprocessing\r",
    "\r",
    "We use Tidymodels to build a recipe for data preprocessing:\r",
    " -   remove correlated variables\r",
    " -   remove non informative variables (zero variance)\r",
    " -   upsampling to handle output class imbalance\n",
    " -   standardize all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e08853-bca5-4681-8e16-6b35c10025e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_recipe <- rf_train %>%\n",
    "  recipe(Outcome ~ .) %>%\n",
    "  step_corr(all_predictors(), threshold = 0.99) %>%\n",
    "  step_zv(all_numeric(), -all_outcomes()) %>%\n",
    "  step_upsample(Outcome, over_ratio = 1, seed = 123) %>%  \n",
    "  step_normalize(all_numeric(), -all_outcomes())\n",
    "\n",
    "prep_rf <- prep(rf_recipe)\n",
    "print(prep_rf)\n",
    "\n",
    "training_set <- juice(prep_rf) # Extract transformed training set\n",
    "head(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48af0359-8693-47b5-a569-f54091f11edc",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcf59f7-9145-4950-8c10-fb8b6e1793bf",
   "metadata": {},
   "source": [
    "### Model training\n",
    "We now specify the structure of our model:\r",
    "-   hyperparameters to tune: `mtry` (number of features to sample for each tree) and `min_n` (minimum number of data points in a node to allow further splitting)\r",
    "-   number of trees in the forest\r",
    "-   the problem at hand (classification)\r",
    "-   the engine (R package)\r",
    "\r",
    "Then we put this in a workflow together with the preprocessing recipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6832413-a8cf-4411-a307-e11489cddd2a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tune_spec <- rand_forest(\n",
    "  mtry = tune(),\n",
    "  trees = 500,\n",
    "  min_n = tune()\n",
    ") %>%\n",
    "  set_mode(\"classification\") %>%\n",
    "  set_engine(\"randomForest\")\n",
    "\n",
    "tune_wf <- workflow() %>%\n",
    "  add_formula(Outcome ~ .) %>%\n",
    "  add_model(tune_spec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16df3d78-f513-471c-974e-a71ebe4e629f",
   "metadata": {},
   "source": [
    "### Tuning of hyperparameters\n",
    "We use k-fold cross-validation to tune the hyperparameters in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabd392b-8890-4705-98ee-3c4e76334568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters \"k_folds\" and \"nrepeats_cv\" will be applied to choose number of folds in (repeated) K-fold crossvalidation \n",
    "# and number of k-fold crossvalidation repeats during model training.\n",
    "# Several metrics (e.g. accuracy, AUC, MCC) will be calculated.\n",
    "\n",
    "set.seed(123)\n",
    "trees_folds <- vfold_cv(training_set, v = k_folds, repeats = nrepeats_cv)\n",
    "\n",
    "# In Random Forest models, mtry is the number of features randomly selected at each split.\n",
    "# A common rule of thumb for classification is √p, where p is the number of predictors (excluding the target).\n",
    "# ncol(training_set)-1 excludes the target variable from the count.\n",
    "\n",
    "m <- round(sqrt(ncol(training_set)-1),0)\n",
    "print(m)\n",
    "\n",
    "rf_grid <- grid_regular(\n",
    "  mtry(range = c(m-5, m+5)),\n",
    "  min_n(range = c(2, 10)),\n",
    "  levels = c(5,5) # 5 different values will be generated evenly spaced between m-5 and m+5 (mtry) and 2 and 10  (min_n)\n",
    ")\n",
    "\n",
    "# Displays the first few rows of the grid and the total number of combinations.\n",
    "\n",
    "head(rf_grid)\n",
    "nrow(rf_grid)\n",
    "\n",
    "# Performs model tuning using the tune_wf workflow.\n",
    "# Evaluation metrics:\n",
    "# - roc_auc: Area Under the ROC Curve.\n",
    "# - accuracy: Overall classification accuracy.\n",
    "# - mcc: Matthews Correlation Coefficient (great for imbalanced datasets).\n",
    "\n",
    "regular_res <- tune_grid(\n",
    "  tune_wf,\n",
    "  metrics = metric_set(roc_auc, accuracy, mcc),\n",
    "  resamples = trees_folds,  # provides the cross-validation strategy\n",
    "  grid = rf_grid\n",
    ")\n",
    "\n",
    "# Collects and prints the average performance metrics for each combination of hyperparameters\n",
    "\n",
    "regular_res |>\n",
    "  collect_metrics() |>\n",
    "  print()\n",
    "\n",
    "\n",
    "# Plots the MCC metric across different values of mtry, grouped by min_n.\n",
    "# Helps visualize which hyperparameter combinations performed best.\n",
    "\n",
    "library(\"repr\")\n",
    "options(repr.plot.width=14, repr.plot.height=8)\n",
    "\n",
    "regular_res %>%\n",
    "  collect_metrics() %>%\n",
    "  filter(.metric == \"mcc\") %>%\n",
    "  mutate(min_n = factor(min_n)) %>%\n",
    "  ggplot(aes(mtry, mean, color = min_n)) +\n",
    "  geom_line(alpha = 0.5, size = 1.5) +\n",
    "  geom_point() +\n",
    "  labs(y = \"mcc\")\n",
    "\n",
    "# Selects the best performing parameter set based on the MCC score.\n",
    "\n",
    "best_auc <- select_best(x = regular_res, metric = \"mcc\")\n",
    "show_best(regular_res, metric = \"mcc\") # Lists the top combinations ranked by MCC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420a216b-09d9-447e-bfd3-4346a2d0f498",
   "metadata": {},
   "source": [
    "### Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2e4073-d726-42d3-bc10-1518e8050395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It replaces the placeholders with the best values, creating the final tuned model.\n",
    "\n",
    "final_rf <- finalize_model(\n",
    "  tune_spec,  # your model specification with placeholder hyperparameters\n",
    "  best_auc  # the best hyperparameter combination found during tuning (in this case, chosen using MCC metric earlier)\n",
    ")\n",
    "\n",
    "print(final_rf)\n",
    "\n",
    "\n",
    "# Finalise the workflow including the final RF model and fit it to the initial split (training and test data):\n",
    "\n",
    "final_wf <- workflow() %>%\n",
    "  add_recipe(rf_recipe) %>%\n",
    "  add_model(final_rf)\n",
    "\n",
    "# Fits the finalized workflow to the training portion of rf_split and evaluates the model on the test portion of rf_split.\n",
    "\n",
    "final_res <- final_wf %>%\n",
    "  last_fit(rf_split, metrics = metric_set(roc_auc, accuracy, mcc, brier_class))\n",
    "\n",
    "# Evaluate the fine-tuned rf model\n",
    "\n",
    "print(final_res)\n",
    "final_res %>%\n",
    "  collect_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c694c2e-93e2-4738-9e7a-19535948dd43",
   "metadata": {},
   "source": [
    "## Get variable importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d20c1a-6f18-461b-9b33-fec05dfd0752",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_res %>% \n",
    "  pluck(\".workflow\", 1) %>%   \n",
    "  extract_fit_parsnip() %>% \n",
    "  vip(num_features = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c659538c-43d7-471b-bb51-b0152203076a",
   "metadata": {},
   "source": [
    "## Predictions on test set\n",
    "\n",
    "The predictive ability of the ML methods on the test set (final evaluation of model performance) will be assessed based on several metrics obtained from the confusion matrix, including accuracy, sensitivity, specificity and the Matthew’s Correlation Coefficient (\"MCC\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374018b0-5f99-4bd9-b29c-bb666bb4f3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We collect the predictions on the test set\n",
    "\n",
    "final_res %>%\n",
    "  collect_predictions()\n",
    "\n",
    "cm <- final_res %>%\n",
    "  collect_predictions() %>%\n",
    "  conf_mat(Outcome, .pred_class)\n",
    "\n",
    "print(cm)\n",
    "\n",
    "# Calculate classification metrics on test set\n",
    "# \"Bacteria\" is the positive class when using event_level = \"second\"\n",
    "\n",
    "test_metrics <- final_res %>%\n",
    "  collect_predictions() %>%\n",
    "  summarise(\n",
    "    accuracy = accuracy_vec(truth = Outcome, estimate = .pred_class),\n",
    "    sensitivity = sens_vec(truth = Outcome, estimate = .pred_class, event_level = \"second\"),\n",
    "    specificity = spec_vec(truth = Outcome, estimate = .pred_class, event_level = \"second\"),\n",
    "    mcc = mcc_vec(truth = Outcome, estimate = .pred_class)\n",
    "  )\n",
    "\n",
    "print(\"Test set metrics:\")\n",
    "print(test_metrics)\n",
    "\n",
    "\n",
    "print(\"DONE!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4761ad23-84b7-4a9b-b469-aaf31e6eb47f",
   "metadata": {},
   "source": [
    "## Save workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e72e20c5-efaa-401d-bc26-6645c2120fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "save.image(\"rf_workshop.RData\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
